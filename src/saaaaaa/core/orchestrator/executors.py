"""Advanced Data Flow Executors for Orchestration

This module implements a sophisticated orchestration system for executing analysis
methods across policy documents. The executor framework provides:

- Dynamic method sequencing with dependency resolution
- Parallel execution optimization for independent methods
- Calibration-aware execution with adaptive thresholding
- Signal registry integration for tracking method results
- Comprehensive error handling and retry mechanisms
- Telemetry and observability through OpenTelemetry integration

Architecture:
-------------
The executor system uses a hierarchical design:

1. ExecutorBase: Abstract base class defining the core execution interface
2. AdvancedDataFlowExecutor: Main implementation with calibration integration
3. Question-specific executors (D1Q1_Executor, D1Q2_Executor, etc.): Specialized
   executors for each question in the policy assessment questionnaire

Method Sequencing:
------------------
The executor determines optimal method execution order by:
- Analyzing method dependencies through input/output requirements
- Detecting independent methods that can execute in parallel
- Applying calibration scores to skip low-quality methods (threshold: 0.3)
- Using retry logic with exponential backoff for transient failures

This approach reduces total execution time by executing independent methods
concurrently while maintaining correctness through dependency ordering.

Calibration Integration:
------------------------
When a CalibrationOrchestrator is provided, executors:
- Query calibration scores for each method before execution
- Skip methods scoring below CALIBRATION_SKIP_THRESHOLD (0.3)
- Log calibration decisions for traceability
- Propagate calibration metadata through the execution pipeline

Performance Characteristics:
----------------------------
- Single Question Executor: 50-200ms (varies by question complexity)
- Batch Execution (5 questions): 300-1000ms
- Batch Execution (30 questions): 2-5 seconds
- Calibration lookup overhead: ~5-10ms per method
- Dependency resolution: ~50-100ms for complex graphs

Memory Requirements:
--------------------
- Base Memory per Executor: ~10MB
- Method result caching: ~5-10MB per 100 results
- Dependency graph storage: ~1-5MB (scales with method count)
- Signal registry: ~20-50MB (depends on signal count and size)
- Total for Full Orchestrator: ~50-100MB
- Large Documents (10MB+): Additional 50-100MB working memory

Configuration:
--------------
Executors require an ExecutorConfig object that specifies:
- timeout_s: Maximum execution time per method (seconds, default: 300.0)
- retry_count: Number of retry attempts for failed methods (default: 3)
- seed: Random seed for deterministic execution (optional)
- advanced_modules: Configuration for optional advanced features

See ExecutorConfig and AdvancedModuleConfig for complete parameter documentation.
"""

import asyncio
import logging
import math
import threading
import time
from abc import ABC, abstractmethod
from collections import defaultdict
from collections.abc import Callable
from contextlib import contextmanager
from dataclasses import dataclass, field
from itertools import chain
import inspect
import os
from typing import Any, Generic, TypeVar

import numpy as np

# Contract infrastructure - ACTUAL INTEGRATION
from ...utils.determinism_helpers import deterministic

from .executor_config import ExecutorConfig, CONSERVATIVE_CONFIG
from .calibration_registry import resolve_calibration
from .advanced_module_config import (
    AdvancedModuleConfig,
    DEFAULT_ADVANCED_CONFIG,
    CONSERVATIVE_ADVANCED_CONFIG,
)
from .signal_consumption import SignalConsumptionProof

# NEW: Calibration system imports
try:
    from saaaaaa.core.calibration import CalibrationOrchestrator
    HAS_CALIBRATION = True
except ImportError:
    CalibrationOrchestrator = None  # type: ignore
    HAS_CALIBRATION = False

try:
    from opentelemetry import trace
    from opentelemetry.trace import Status, StatusCode
    tracer = trace.get_tracer(__name__)
    HAS_OTEL = True
except ImportError:
    tracer = None
    HAS_OTEL = False

try:  # Optional imports for advanced context propagation
    import networkx as nx
except Exception:  # pragma: no cover - optional dependency at runtime
    nx = None  # type: ignore[assignment]

try:  # TeorÃ­a de Cambio categorical enrichment
    from saaaaaa.analysis.teoria_cambio import CategoriaCausal  # type: ignore
except Exception:  # pragma: no cover - avoid hard failure if module unavailable
    CategoriaCausal = None  # type: ignore[assignment]

# ============================================================================
# LOGGING AND METRICS SETUP
# ============================================================================

logger = logging.getLogger(__name__)


# ============================================================================
# DETERMINISTIC EXECUTION CONTEXT
# ============================================================================

@dataclass
class DeterministicSeeds:
    """Container for deterministic seeds used within an execution context."""
    np: int  # Seed for numpy RNG
    python: int  # Seed for Python random
    
    
@contextmanager
def deterministic(policy_unit_id: str | None, correlation_id: str | None):
    """
    Deterministic execution context manager.
    
    Provides stable seeds derived from policy_unit_id and correlation_id.
    For the same (policy_unit_id, correlation_id), guarantees bit-for-bit
    reproducible execution of stochastic operations.
    
    Usage:
        with deterministic(policy_unit_id, correlation_id) as seeds:
            rng = np.random.default_rng(seeds.np)
            # Use rng for all stochastic operations
    
    Args:
        policy_unit_id: Policy unit identifier
        correlation_id: Correlation identifier
        
    Yields:
        DeterministicSeeds with .np and .python attributes
    """
    import hashlib
    import random
    
    # Derive deterministic seed from identifiers
    components = [
        str(policy_unit_id) if policy_unit_id else "NO_POLICY_UNIT",
        str(correlation_id) if correlation_id else "NO_CORRELATION",
    ]
    material = "|".join(components)
    digest = hashlib.sha256(material.encode("utf-8")).digest()
    base_seed = int.from_bytes(digest[:4], byteorder="big")
    
    seeds = DeterministicSeeds(
        np=base_seed,
        python=base_seed + 1,
    )
    
    # Seed Python's random module for deterministic execution
    random.seed(seeds.python)
    
    yield seeds


def _ensure_rng(rng: np.random.Generator | None) -> np.random.Generator:
    """
    Ensure a valid RNG generator is available.
    
    If rng is None, creates a new default generator.
    Otherwise, returns the provided rng.
    
    Args:
        rng: Optional numpy random generator
        
    Returns:
        A valid numpy random generator
    """
    if rng is None:
        return np.random.default_rng()
    return rng


class CircuitBreakerState:
    """Async-safe circuit breaker state for fault isolation."""
    
    def __init__(self):
        self.failures = 0
        self.open = False
        self._lock = asyncio.Lock()
        self._state_changes: list[dict[str, Any]] = []
        self._max_history = 100

    async def increment_failures(self):
        """Increment failure count and potentially open circuit."""
        async with self._lock:
            old_open = self.open
            self.failures += 1
            if self.failures >= 3:
                self.open = True
            
            # Record state change
            if old_open != self.open:
                self._state_changes.append({
                    'timestamp': time.time(),
                    'from_open': old_open,
                    'to_open': self.open,
                    'failures': self.failures,
                })
                
                # Trim history
                if len(self._state_changes) > self._max_history:
                    self._state_changes = self._state_changes[-self._max_history:]
                
                logger.warning(
                    "circuit_breaker_state_change",
                    extra={
                        "old_open": old_open,
                        "new_open": self.open,
                        "failures": self.failures,
                    }
                )
    
    async def reset(self):
        """Reset circuit breaker state."""
        async with self._lock:
            old_open = self.open
            self.failures = 0
            self.open = False
            
            # Record state change if circuit was open
            if old_open:
                self._state_changes.append({
                    'timestamp': time.time(),
                    'from_open': old_open,
                    'to_open': False,
                    'failures': 0,
                })
                
                # Trim history
                if len(self._state_changes) > self._max_history:
                    self._state_changes = self._state_changes[-self._max_history:]
    
    async def is_open(self) -> bool:
        """Check if circuit is open."""
        async with self._lock:
            return self.open
    
    def get_state_history(self) -> list[dict[str, Any]]:
        """Get history of state changes for monitoring."""
        return list(self._state_changes)


@dataclass
class ExecutionMetrics:
    """Metrics for monitoring executor performance"""
    total_executions: int = 0
    successful_executions: int = 0
    failed_executions: int = 0
    total_execution_time: float = 0.0
    quantum_optimizations: int = 0
    quantum_convergence_times: list[float] = field(default_factory=list)
    meta_learner_strategy_selections: dict[int, int] = field(default_factory=dict)
    information_bottlenecks_detected: int = 0
    retry_attempts: int = 0
    method_execution_times: dict[str, list[float]] = field(default_factory=dict)

    def record_execution(self, success: bool, execution_time: float, method_key: str = None) -> None:
        """Record an execution attempt"""
        with _metrics_lock:
            self.total_executions += 1
            if success:
                self.successful_executions += 1
            else:
                self.failed_executions += 1
            self.total_execution_time += execution_time
            if method_key:
                if method_key not in self.method_execution_times:
                    self.method_execution_times[method_key] = []
                self.method_execution_times[method_key].append(execution_time)

    def record_quantum_optimization(self, convergence_time: float) -> None:
        """Record quantum optimization metrics"""
        with _metrics_lock:
            self.quantum_optimizations += 1
            self.quantum_convergence_times.append(convergence_time)

    def record_meta_learner_selection(self, strategy_idx: int) -> None:
        """Record meta-learner strategy selection"""
        with _metrics_lock:
            if strategy_idx not in self.meta_learner_strategy_selections:
                self.meta_learner_strategy_selections[strategy_idx] = 0
            self.meta_learner_strategy_selections[strategy_idx] += 1

    def record_information_bottleneck(self) -> None:
        """Record information bottleneck detection"""
        with _metrics_lock:
            self.information_bottlenecks_detected += 1

    def record_retry(self) -> None:
        """Record retry attempt"""
        with _metrics_lock:
            self.retry_attempts += 1

    def get_summary(self) -> dict[str, Any]:
        """Get metrics summary"""
        return {
            'total_executions': self.total_executions,
            'successful_executions': self.successful_executions,
            'failed_executions': self.failed_executions,
            'success_rate': self.successful_executions / max(self.total_executions, 1),
            'total_execution_time': self.total_execution_time,
            'avg_execution_time': self.total_execution_time / max(self.total_executions, 1),
            'quantum_optimizations': self.quantum_optimizations,
            'avg_quantum_convergence_time': np.mean(self.quantum_convergence_times) if self.quantum_convergence_times else 0.0,
            'meta_learner_strategies': dict(self.meta_learner_strategy_selections),
            'information_bottlenecks_detected': self.information_bottlenecks_detected,
            'retry_attempts': self.retry_attempts,
        }

# Global metrics instance with thread-safety
_global_metrics = ExecutionMetrics()
_metrics_lock = threading.RLock()
_ARG_UNSET: object = object()

def get_execution_metrics() -> ExecutionMetrics:
    """Get global execution metrics"""
    return _global_metrics

@contextmanager
def execution_timer(operation_name: str):
    """Context manager for timing operations"""
    start_time = time.time()
    try:
        yield
    finally:
        elapsed = time.time() - start_time
        logger.debug(f"{operation_name} completed in {elapsed:.3f}s")

# ============================================================================
# QUANTUM-INSPIRED OPTIMIZATION
# ============================================================================

class QuantumState:
    """Quantum-inspired state for execution path optimization"""

    def __init__(self, dimension: int) -> None:
        self.dimension = dimension
        self.amplitudes = np.ones(dimension, dtype=complex) / np.sqrt(dimension)
        self.phase = np.zeros(dimension)

    def apply_oracle(self, marked_states: list[int]) -> None:
        """Apply oracle function to mark optimal states"""
        for state in marked_states:
            if 0 <= state < self.dimension:
                self.amplitudes[state] *= -1

    def apply_diffusion(self) -> None:
        """Apply Grover diffusion operator"""
        avg = np.mean(self.amplitudes)
        self.amplitudes = 2 * avg - self.amplitudes

    def measure(self, rng: np.random.Generator | None = None) -> int:
        """Collapse to measured state"""
        rng = _ensure_rng(rng)
        probabilities = np.abs(self.amplitudes) ** 2
        probabilities /= probabilities.sum()
        return rng.choice(self.dimension, p=probabilities)

    def optimize_path(self, iterations: int = 3, rng: np.random.Generator | None = None) -> int:
        """Find optimal execution path using Grover-inspired search"""
        rng = _ensure_rng(rng)
        for _ in range(iterations):
            self.apply_diffusion()
        return self.measure(rng=rng)

class QuantumExecutionOptimizer:
    """Quantum-inspired optimizer for execution path selection

    Instrumentation:
    - Tracks convergence times for quantum optimization
    - Records optimization attempts and success rates
    """

    def __init__(self, num_methods: int) -> None:
        self.num_methods = num_methods
        self.state = QuantumState(num_methods)
        self.execution_history: list[tuple[int, float]] = []

    def select_optimal_path(self, available_methods: list[int], rng: np.random.Generator | None = None) -> list[int]:
        """Select optimal execution path using quantum annealing principles"""
        rng = _ensure_rng(rng)
        start_time = time.time()

        if self.execution_history:
            top_methods = sorted(self.execution_history, key=lambda x: x[1], reverse=True)
            marked = [m[0] for m in top_methods[:len(top_methods) // 3]]
            self.state.apply_oracle(marked)

        optimal_idx = self.state.optimize_path(rng=rng)
        path = self._construct_path(optimal_idx, available_methods, rng=rng)

        # Record convergence time
        convergence_time = time.time() - start_time
        _global_metrics.record_quantum_optimization(convergence_time)
        logger.debug(f"Quantum optimization converged in {convergence_time:.4f}s, path length: {len(path)}")

        return path

    def _construct_path(self, start_idx: int, available: list[int], rng: np.random.Generator | None = None) -> list[int]:
        """Construct execution path from starting point"""
        rng = _ensure_rng(rng)
        if not available:
            return []
        path = [available[start_idx % len(available)]]
        remaining = [m for m in available if m not in path]

        while remaining and len(path) < len(available):
            probs = self._tunneling_probabilities(path[-1], remaining)
            next_method = rng.choice(remaining, p=probs)
            path.append(next_method)
            remaining.remove(next_method)

        return path

    def _tunneling_probabilities(self, current: int, candidates: list[int]) -> np.ndarray:
        """Calculate quantum tunneling probabilities to candidate states"""
        distances = np.array([abs(current - c) for c in candidates])
        probs = np.exp(-distances / self.num_methods)
        return probs / probs.sum()

    def update_performance(self, method_idx: int, performance: float) -> None:
        """Update execution history with performance metrics"""
        self.execution_history.append((method_idx, performance))

# ============================================================================
# NEUROMORPHIC COMPUTING PATTERNS
# ============================================================================

class SpikingNeuron:
    """Spiking neuron for neuromorphic data flow control"""

    def __init__(self, threshold: float = 1.0, decay: float = 0.9) -> None:
        self.potential = 0.0
        self.threshold = threshold
        self.decay = decay
        self.spike_history: list[float] = []

    def receive_input(self, signal: float) -> bool:
        """Receive input signal and check for spike"""
        self.potential += signal

        if self.potential >= self.threshold:
            self.spike_history.append(1.0)
            self.potential = 0.0
            return True

        self.potential *= self.decay
        self.spike_history.append(0.0)
        return False

    def get_firing_rate(self, window: int = 10) -> float:
        """Calculate recent firing rate"""
        if len(self.spike_history) < window:
            return 0.0
        return sum(self.spike_history[-window:]) / window

class NeuromorphicFlowController:
    """Neuromorphic controller for dynamic data flow"""

    def __init__(self, num_stages: int, seed: int | None = None) -> None:
        self.neurons = [SpikingNeuron() for _ in range(num_stages)]
        rng = np.random.default_rng(seed)
        self.synaptic_weights = rng.random((num_stages, num_stages)) * 0.5
        self.stdp_learning_rate = 0.01

    def process_data_flow(self, data_quality: list[float]) -> list[bool]:
        """Process data flow through neuromorphic network"""
        activations = []

        for i, quality in enumerate(data_quality):
            spike = self.neurons[i].receive_input(quality)
            activations.append(spike)

            if spike:
                for j in range(i + 1, len(self.neurons)):
                    self.neurons[j].receive_input(self.synaptic_weights[i, j])

        return activations

    def apply_stdp(self, pre_idx: int, post_idx: int, pre_spike: bool, post_spike: bool) -> None:
        """Apply spike-timing-dependent plasticity"""
        if pre_spike and post_spike:
            self.synaptic_weights[pre_idx, post_idx] *= (1 + self.stdp_learning_rate)
        elif pre_spike and not post_spike:
            self.synaptic_weights[pre_idx, post_idx] *= (1 - self.stdp_learning_rate)

        self.synaptic_weights[pre_idx, post_idx] = np.clip(
            self.synaptic_weights[pre_idx, post_idx], 0.0, 1.0
        )

    def adapt_flow(self, performance_metrics: list[float]) -> None:
        """Adapt flow based on performance using neuromorphic learning"""
        for i in range(len(self.neurons) - 1):
            pre_rate = self.neurons[i].get_firing_rate()
            post_rate = self.neurons[i + 1].get_firing_rate()
            self.apply_stdp(i, i + 1, pre_rate > 0.5, post_rate > 0.5)

# ============================================================================
# CAUSAL INFERENCE FRAMEWORK
# ============================================================================

class CausalGraph:
    """Causal graph for dependency resolution using PC algorithm"""

    def __init__(self, num_variables: int) -> None:
        self.num_variables = num_variables
        self.adjacency = np.zeros((num_variables, num_variables), dtype=int)
        self.separating_sets = {}

    def learn_structure(self, data: np.ndarray, alpha: float = 0.05) -> None:
        """Learn causal structure using PC algorithm"""
        self.adjacency = np.ones((self.num_variables, self.num_variables), dtype=int)
        np.fill_diagonal(self.adjacency, 0)

        for i in range(self.num_variables):
            for j in range(i + 1, self.num_variables):
                if self.adjacency[i, j] == 0:
                    continue

                if self._test_independence(data, i, j, set(), alpha):
                    self.adjacency[i, j] = 0
                    self.adjacency[j, i] = 0
                    self.separating_sets[(i, j)] = set()

        for size in range(1, self.num_variables - 1):
            for i in range(self.num_variables):
                neighbors = self._get_neighbors(i)
                if len(neighbors) < size:
                    continue

                for j in neighbors:
                    for cond_set in self._subsets(neighbors - {j}, size):
                        if self._test_independence(data, i, j, cond_set, alpha):
                            self.adjacency[i, j] = 0
                            self.adjacency[j, i] = 0
                            self.separating_sets[(i, j)] = cond_set
                            break

    def _test_independence(self, data: np.ndarray, i: int, j: int,
                           cond_set: set, alpha: float) -> bool:
        """Test conditional independence using partial correlation"""
        if len(cond_set) == 0:
            corr = np.corrcoef(data[:, i], data[:, j])[0, 1]
        else:
            cond_indices = list(cond_set)
            corr = self._partial_correlation(data, i, j, cond_indices)

        n = len(data)
        z = 0.5 * np.log((1 + corr) / (1 - corr))
        p_value = 2 * (1 - self._normal_cdf(abs(z) * np.sqrt(n - len(cond_set) - 3)))

        return p_value > alpha

    def _partial_correlation(self, data: np.ndarray, i: int, j: int,
                             cond: list[int]) -> float:
        """Calculate partial correlation"""
        if len(cond) == 0:
            return np.corrcoef(data[:, i], data[:, j])[0, 1]

        k = cond[0]
        remaining = cond[1:]

        r_ij_rest = self._partial_correlation(data, i, j, remaining)
        r_ik_rest = self._partial_correlation(data, i, k, remaining)
        r_jk_rest = self._partial_correlation(data, j, k, remaining)

        numerator = r_ij_rest - r_ik_rest * r_jk_rest
        denominator = np.sqrt((1 - r_ik_rest ** 2) * (1 - r_jk_rest ** 2))

        return numerator / denominator if denominator > 1e-10 else 0.0

    def _normal_cdf(self, x: float) -> float:
        """Standard normal CDF approximation"""
        return 0.5 * (1 + math.erf(x / np.sqrt(2)))

    def _get_neighbors(self, node: int) -> set:
        """Get neighboring nodes"""
        return {j for j in range(self.num_variables) if self.adjacency[node, j] == 1}

    def _subsets(self, s: set, size: int):
        """Generate all subsets of given size"""
        from itertools import combinations
        return [set(c) for c in combinations(s, size)]

    def get_execution_order(self) -> list[int]:
        """Get topological execution order"""
        in_degree = self.adjacency.sum(axis=0)
        order = []
        available = {i for i in range(self.num_variables) if in_degree[i] == 0}

        while available:
            node = available.pop()
            order.append(node)

            for j in range(self.num_variables):
                if self.adjacency[node, j] == 1:
                    in_degree[j] -= 1
                    if in_degree[j] == 0:
                        available.add(j)

        return order if len(order) == self.num_variables else list(range(self.num_variables))

# ============================================================================
# INFORMATION-THEORETIC FLOW OPTIMIZATION
# ============================================================================

class InformationFlowOptimizer:
    """Optimize data flow using information theory principles"""

    def __init__(self, num_stages: int) -> None:
        self.num_stages = num_stages
        self.mutual_information_matrix = np.zeros((num_stages, num_stages))
        self.entropy_history: list[float] = []

    def calculate_entropy(self, data: Any) -> float:
        """Calculate Shannon entropy of data"""
        if data is None:
            return 0.0

        data_str = str(data)
        freq = defaultdict(int)
        for char in data_str:
            freq[char] += 1

        total = len(data_str)
        entropy = -sum((count / total) * np.log2(count / total)
                       for count in freq.values() if count > 0)

        return entropy

    def calculate_mutual_information(self, data1: Any, data2: Any) -> float:
        """Calculate mutual information between two data streams"""
        h1 = self.calculate_entropy(data1)
        h2 = self.calculate_entropy(data2)

        combined = str(data1) + str(data2)
        h_joint = self.calculate_entropy(combined)

        mi = h1 + h2 - h_joint
        return max(0.0, mi)

    def update_flow_metrics(self, stage: int, data: Any) -> None:
        """Update information flow metrics"""
        entropy = self.calculate_entropy(data)
        self.entropy_history.append(entropy)

        if len(self.entropy_history) > stage:
            for prev_stage in range(stage):
                if prev_stage < len(self.entropy_history) - 1:
                    prev_data = self.entropy_history[prev_stage]
                    mi = self.calculate_mutual_information(prev_data, entropy)
                    self.mutual_information_matrix[prev_stage, stage] = mi

    def get_information_bottlenecks(self) -> list[int]:
        """Identify information bottlenecks in the flow

        Instrumentation: Records bottleneck detection events
        """
        bottlenecks = []

        if len(self.entropy_history) < 2:
            return bottlenecks

        gradients = np.diff(self.entropy_history)
        threshold = np.mean(gradients) - np.std(gradients)
        for i, grad in enumerate(gradients):
            if grad < threshold:
                bottlenecks.append(i + 1)

        # Record bottleneck detection
        if bottlenecks:
            _global_metrics.record_information_bottleneck()
            logger.warning(f"Information bottlenecks detected at stages: {bottlenecks}")

        return bottlenecks

    def optimize_information_flow(self, current_order: list[int]) -> list[int]:
        """
        Reorder execution to maximize information flow using a greedy algorithm.
        
        This method implements a greedy selection strategy that iteratively selects
        the next stage based on mutual information with already-selected stages.
        At each step, it chooses the remaining stage with the highest total mutual
        information with all previously selected stages, creating an execution order
        that maximizes information propagation.
        
        The algorithm is used to optimize method execution order based on data
        dependencies and information transfer between stages.
        
        Args:
            current_order: Initial execution order (list of stage indices)
            
        Returns:
            Optimized execution order maximizing cumulative mutual information
        """
        if len(current_order) <= 1:
            return current_order

        optimized = [current_order[0]]
        remaining = set(current_order[1:])

        while remaining:
            best_next = None
            best_mi = -1

            for candidate in remaining:
                total_mi = sum(self.mutual_information_matrix[s, candidate]
                               for s in optimized if s < self.num_stages and candidate < self.num_stages)

                if total_mi > best_mi:
                    best_mi = total_mi
                    best_next = candidate

            if best_next is not None:
                optimized.append(best_next)
                remaining.remove(best_next)
            else:
                optimized.extend(sorted(remaining))
                break

        return optimized

# ============================================================================
# META-LEARNING EXECUTION STRATEGY
# ============================================================================

class MetaLearningStrategy:
    """Meta-learning strategy for adaptive execution

    Instrumentation:
    - Tracks which strategies are selected most frequently
    - Records strategy performance over time
    
    Parameters from academic research:
    - epsilon: Exploration rate (standard RL: 0.05-0.2)
    - learning_rate: Update rate (Thrun & Pratt 1998: 0.01-0.1)
    """

    def __init__(
        self,
        num_strategies: int = 5,
        epsilon: float = 0.1,
        learning_rate: float = 0.05,
    ) -> None:
        self.num_strategies = num_strategies
        self.strategy_performance = np.ones(num_strategies) / num_strategies
        self.epsilon = epsilon
        self.learning_rate = learning_rate

    def select_strategy(self, rng: np.random.Generator | None = None) -> int:
        """Select execution strategy using epsilon-greedy"""
        rng = _ensure_rng(rng)
        if rng.random() < self.epsilon:
            strategy_idx = rng.integers(0, self.num_strategies)
        else:
            strategy_idx = np.argmax(self.strategy_performance)

        # Record strategy selection
        _global_metrics.record_meta_learner_selection(strategy_idx)
        logger.debug(f"Meta-learner selected strategy {strategy_idx} (performance: {self.strategy_performance[strategy_idx]:.3f})")

        return strategy_idx

    def update_strategy_performance(self, strategy_idx: int, reward: float) -> None:
        """Update strategy performance using exponential moving average"""
        current_perf = self.strategy_performance[strategy_idx]
        self.strategy_performance[strategy_idx] = (
                (1 - self.learning_rate) * current_perf +
                self.learning_rate * reward
        )

        self.strategy_performance /= self.strategy_performance.sum()

        logger.debug(f"Updated strategy {strategy_idx} performance: {current_perf:.3f} -> {self.strategy_performance[strategy_idx]:.3f} (reward: {reward:.3f})")

    def get_strategy_config(self, strategy_idx: int) -> dict[str, Any]:
        """Get configuration for selected strategy"""
        strategies = [
            {"parallel": True, "batch_size": 10, "pruning": False},
            {"parallel": False, "batch_size": 5, "pruning": True},
            {"parallel": True, "batch_size": 1, "pruning": True},
            {"parallel": False, "batch_size": 1, "pruning": False},
            {"parallel": True, "batch_size": 20, "pruning": True},
        ]

        return strategies[strategy_idx % len(strategies)]

# ============================================================================
# ATTENTION MECHANISM
# ============================================================================

class AttentionMechanism:
    """Attention mechanism for focusing computational resources"""

    def __init__(self, embedding_dim: int = 64, seed: int | None = None) -> None:
        self.embedding_dim = embedding_dim
        rng = np.random.default_rng(seed)
        self.query_weights = rng.standard_normal((embedding_dim, embedding_dim)) * 0.01
        self.key_weights = rng.standard_normal((embedding_dim, embedding_dim)) * 0.01
        self.value_weights = rng.standard_normal((embedding_dim, embedding_dim)) * 0.01

    def embed_method(self, method_name: str) -> np.ndarray:
        """Embed method name into vector space"""
        hash_val = hash(method_name)
        rng = np.random.default_rng(hash_val % (2 ** 31))
        embedding = rng.standard_normal(self.embedding_dim)
        return embedding / np.linalg.norm(embedding)

    def compute_attention(self, query_methods: list[str],
                          key_methods: list[str]) -> np.ndarray:
        """Compute attention scores using scaled dot-product attention"""
        Q = np.array([self.embed_method(m) @ self.query_weights for m in query_methods])
        K = np.array([self.embed_method(m) @ self.key_weights for m in key_methods])
        V = np.array([self.embed_method(m) @ self.value_weights for m in key_methods])

        scores = Q @ K.T / np.sqrt(self.embedding_dim)
        attention_weights = self._softmax(scores)

        attention_weights @ V

        return attention_weights

    def _softmax(self, x: np.ndarray) -> np.ndarray:
        """Compute softmax with numerical stability"""
        exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))
        return exp_x / exp_x.sum(axis=-1, keepdims=True)

    def prioritize_methods(self, available_methods: list[str],
                           context_methods: list[str]) -> list[tuple[str, float]]:
        """Prioritize methods based on attention scores"""
        if not available_methods or not context_methods:
            return [(m, 1.0) for m in available_methods]

        attention = self.compute_attention([available_methods[0]], context_methods)
        scores = attention[0]

        method_scores = []
        for i, method in enumerate(available_methods):
            score = scores[i % len(scores)]
            method_scores.append((method, float(score)))

        return sorted(method_scores, key=lambda x: x[1], reverse=True)

# ============================================================================
# TOPOLOGICAL DATA ANALYSIS
# ============================================================================

class PersistentHomology:
    """Persistent homology for understanding data topology"""

    def __init__(self) -> None:
        self.persistence_diagram: list[tuple[float, float]] = []

    def compute_persistence(self, data: np.ndarray, max_dimension: int = 1) -> None:
        """Compute persistence diagram"""
        if len(data) == 0:
            return

        distances = self._pairwise_distances(data)

        for i in range(len(data)):
            for j in range(i + 1, len(data)):
                birth = 0.0
                death = distances[i, j]
                self.persistence_diagram.append((birth, death))

    def _pairwise_distances(self, data: np.ndarray) -> np.ndarray:
        """Compute pairwise distances"""
        n = len(data)
        distances = np.zeros((n, n))

        for i in range(n):
            for j in range(i + 1, n):
                dist = np.linalg.norm(data[i] - data[j])
                distances[i, j] = dist
                distances[j, i] = dist

        return distances

    def get_topological_features(self) -> dict[str, float]:
        """Extract topological features from persistence diagram"""
        if not self.persistence_diagram:
            return {"persistence": 0.0, "num_features": 0}

        lifetimes = [death - birth for birth, death in self.persistence_diagram]

        return {
            "persistence": np.mean(lifetimes),
            "num_features": len(self.persistence_diagram),
            "max_lifetime": max(lifetimes) if lifetimes else 0.0,
            "total_persistence": sum(lifetimes)
        }

# ============================================================================
# CATEGORY THEORY ABSTRACTIONS
# ============================================================================

T = TypeVar('T')
U = TypeVar('U')

class Functor(Generic[T, U], ABC):
    """Functor abstraction for composable transformations"""

    @abstractmethod
    def fmap(self, f: Callable[[T], U]) -> 'Functor[T, U]':
        """Map function over functor"""
        pass

class ExecutionMonad(Functor):
    """Monad for composable execution pipelines"""

    def __init__(self, value: Any) -> None:
        self.value = value
        self.history: list[str] = []

    def fmap(self, f: Callable) -> 'ExecutionMonad':
        """Apply function and wrap result"""
        try:
            result = f(self.value)
            monad = ExecutionMonad(result)
            monad.history = self.history + [f.__name__]
            return monad
        except Exception:
            return ExecutionMonad(None)

    def bind(self, f: Callable[[Any], 'ExecutionMonad']) -> 'ExecutionMonad':
        """Monadic bind operation"""
        if self.value is None:
            return self

        try:
            result_monad = f(self.value)
            result_monad.history = self.history + result_monad.history
            return result_monad
        except Exception:
            return ExecutionMonad(None)

    @staticmethod
    def unit(value: Any) -> 'ExecutionMonad':
        """Lift value into monad"""
        return ExecutionMonad(value)

    def get_value(self) -> Any:
        """Extract value from monad"""
        return self.value

class CategoryTheoryExecutor:
    """Executor using category theory abstractions"""

    def __init__(self) -> None:
        self.morphisms: dict[str, Callable] = {}

    def add_morphism(self, name: str, f: Callable) -> None:
        """Add morphism (function) to category"""
        self.morphisms[name] = f

    def compose(self, *morphism_names: str) -> Callable:
        """Compose morphisms"""
        morphisms = [self.morphisms[name] for name in morphism_names if name in self.morphisms]

        def composed(x):
            result = x
            for f in morphisms:
                result = f(result)
            return result

        return composed

    def execute_pipeline(self, initial_value: Any,
                         morphism_sequence: list[str]) -> ExecutionMonad:
        """Execute pipeline using monadic composition"""
        monad = ExecutionMonad.unit(initial_value)

        for morphism_name in morphism_sequence:
            if morphism_name in self.morphisms:
                monad = monad.bind(lambda x: ExecutionMonad.unit(self.morphisms[morphism_name](x)))

        return monad

# ============================================================================
# PROBABILISTIC PROGRAMMING
# ============================================================================

class ProbabilisticExecutor:
    """Probabilistic programming for uncertainty quantification"""

    def __init__(self) -> None:
        self.distributions: dict[str, Any] = {}
        self.samples: dict[str, list[float]] = defaultdict(list)

    def define_prior(self, param_name: str, distribution: str, **kwargs) -> None:
        """Define prior distribution for parameter"""
        self.distributions[param_name] = (distribution, kwargs)

    def sample_prior(self, param_name: str, rng: np.random.Generator | None = None) -> float:
        """Sample from prior distribution"""
        rng = _ensure_rng(rng)
        if param_name not in self.distributions:
            return 1.0

        dist_type, params = self.distributions[param_name]

        if dist_type == "normal":
            return float(rng.normal(params.get("mean", 0), params.get("std", 1)))
        elif dist_type == "beta":
            return float(rng.beta(params.get("alpha", 2), params.get("beta", 2)))
        elif dist_type == "gamma":
            return float(rng.gamma(params.get("shape", 2), params.get("scale", 1)))
        else:
            return 1.0

    def bayesian_update(self, param_name: str, likelihood: float) -> None:
        """Update posterior using Bayesian inference"""
        if param_name in self.samples:
            prior_sample = self.sample_prior(param_name)
            posterior_sample = prior_sample * likelihood
            self.samples[param_name].append(posterior_sample)

    def get_posterior_mean(self, param_name: str) -> float:
        """Get posterior mean estimate"""
        if param_name not in self.samples or not self.samples[param_name]:
            return self.sample_prior(param_name)

        return np.mean(self.samples[param_name])

    def get_credible_interval(self, param_name: str, alpha: float = 0.95) -> tuple[float, float]:
        """Get credible interval for parameter"""
        if param_name not in self.samples or not self.samples[param_name]:
            return (0.0, 1.0)

        samples = np.array(self.samples[param_name])
        lower = np.percentile(samples, (1 - alpha) / 2 * 100)
        upper = np.percentile(samples, (1 + alpha) / 2 * 100)

        return (float(lower), float(upper))

# ============================================================================
# ADVANCED EXECUTOR BASE CLASS
# ============================================================================

@dataclass
class ValidationResult:
    """Result of executor validation check."""
    is_valid: bool
    severity: str  # ERROR, WARNING, INFO
    message: str
    context: dict[str, Any] = field(default_factory=dict)


class ExecutorBase(ABC):
    """Base class for all executors with pre-flight validation.
    
    This class provides the foundational validation logic that all executors
    must implement before execution. It ensures that:
    1. All dependencies are available
    2. Calibrations are properly configured
    3. Required resources are accessible
    """
    
    def validate_before_execution(self) -> ValidationResult:
        """Perform pre-flight checks before execution.
        
        This method validates:
        1. All class dependencies exist in the executor registry
        2. All methods have proper calibration entries
        3. Required resources (config, signal registry) are available
        
        Returns:
            ValidationResult: Object indicating validation success or failure
        """
        errors = []
        warnings = []
        context_info = {}
        
        # Check 1: Verify all dependencies exist
        try:
            dependency_result = self._check_dependencies()
            if not dependency_result.is_valid:
                errors.append(dependency_result.message)
                context_info.update(dependency_result.context)
            elif dependency_result.severity == "WARNING":
                warnings.append(dependency_result.message)
        except Exception as e:
            errors.append(f"Dependency check failed: {str(e)}")
        
        # Check 2: Verify calibration available
        try:
            calibration_result = self._check_calibration()
            if not calibration_result.is_valid:
                errors.append(calibration_result.message)
                context_info.update(calibration_result.context)
            elif calibration_result.severity == "WARNING":
                warnings.append(calibration_result.message)
        except Exception as e:
            errors.append(f"Calibration check failed: {str(e)}")
        
        # Check 3: Ensure resources available
        try:
            resource_result = self._check_resources()
            if not resource_result.is_valid:
                errors.append(resource_result.message)
                context_info.update(resource_result.context)
            elif resource_result.severity == "WARNING":
                warnings.append(resource_result.message)
        except Exception as e:
            errors.append(f"Resource check failed: {str(e)}")
        
        # Compile final result
        if errors:
            return ValidationResult(
                is_valid=False,
                severity="ERROR",
                message="; ".join(errors),
                context=context_info
            )
        elif warnings:
            return ValidationResult(
                is_valid=True,
                severity="WARNING",
                message="; ".join(warnings),
                context=context_info
            )
        else:
            return ValidationResult(
                is_valid=True,
                severity="INFO",
                message="All pre-flight checks passed",
                context=context_info
            )
    
    def _check_dependencies(self) -> ValidationResult:
        """Check that all class dependencies exist in executor registry.
        
        Returns:
            ValidationResult indicating if dependencies are satisfied
        """
        if not hasattr(self, 'executor') or self.executor is None:
            return ValidationResult(
                is_valid=False,
                severity="ERROR",
                message="Method executor not initialized",
                context={"check": "dependencies"}
            )
        
        seq = self._get_method_sequence()
        missing_classes = []
        
        for class_name, method_name in seq:
            if not hasattr(self.executor, 'instances'):
                return ValidationResult(
                    is_valid=False,
                    severity="ERROR",
                    message="Executor does not have instances registry",
                    context={"check": "dependencies"}
                )
            
            if class_name not in self.executor.instances:
                missing_classes.append(class_name)
        
        if missing_classes:
            return ValidationResult(
                is_valid=False,
                severity="ERROR",
                message=f"Missing class dependencies: {', '.join(missing_classes)}",
                context={
                    "check": "dependencies",
                    "missing_classes": missing_classes,
                    "total_required": len(seq)
                }
            )
        
        return ValidationResult(
            is_valid=True,
            severity="INFO",
            message=f"All {len(seq)} class dependencies available",
            context={
                "check": "dependencies",
                "classes_checked": len(set(c for c, _ in seq))
            }
        )
    
    def _check_calibration(self) -> ValidationResult:
        """Check that all methods have proper calibration entries.
        
        Returns:
            ValidationResult indicating if calibrations are available
        """
        seq = self._get_method_sequence()
        missing_calibrations = []
        default_calibrations = []
        
        for class_name, method_name in seq:
            calib = resolve_calibration(class_name, method_name, strict=False)
            if calib is None:
                missing_calibrations.append(f"{class_name}.{method_name}")
            elif calib.is_default_like():
                default_calibrations.append(f"{class_name}.{method_name}")
        
        if missing_calibrations:
            return ValidationResult(
                is_valid=False,
                severity="ERROR",
                message=f"Missing calibrations for {len(missing_calibrations)} methods",
                context={
                    "check": "calibration",
                    "missing_calibrations": missing_calibrations[:5],  # First 5 for brevity
                    "total_missing": len(missing_calibrations)
                }
            )
        
        if default_calibrations:
            return ValidationResult(
                is_valid=True,
                severity="WARNING",
                message=f"Using default calibrations for {len(default_calibrations)} methods",
                context={
                    "check": "calibration",
                    "default_calibrations": default_calibrations[:5],
                    "total_defaults": len(default_calibrations)
                }
            )
        
        return ValidationResult(
            is_valid=True,
            severity="INFO",
            message=f"All {len(seq)} methods have explicit calibrations",
            context={
                "check": "calibration",
                "methods_checked": len(seq)
            }
        )
    
    def _check_resources(self) -> ValidationResult:
        """Check that required resources are available.
        
        Returns:
            ValidationResult indicating if resources are available
        """
        issues = []
        warnings = []
        
        # Check config
        if not hasattr(self, 'config') or self.config is None:
            issues.append("ExecutorConfig not initialized")
        
        # Check signal registry (optional but recommended)
        if not hasattr(self, 'signal_registry') or self.signal_registry is None:
            warnings.append("Signal registry not available (optional)")
        
        # Check method executor
        if not hasattr(self, 'executor') or self.executor is None:
            issues.append("Method executor not initialized")
        
        if issues:
            return ValidationResult(
                is_valid=False,
                severity="ERROR",
                message="; ".join(issues),
                context={
                    "check": "resources",
                    "issues": issues,
                    "warnings": warnings
                }
            )
        
        if warnings:
            return ValidationResult(
                is_valid=True,
                severity="WARNING",
                message="; ".join(warnings),
                context={
                    "check": "resources",
                    "warnings": warnings
                }
            )
        
        return ValidationResult(
            is_valid=True,
            severity="INFO",
            message="All required resources available",
            context={"check": "resources"}
        )
    
    @abstractmethod
    def _get_method_sequence(self) -> list[tuple[str, str]]:
        """Return the method sequence for this executor.
        
        Returns:
            List of (class_name, method_name) tuples
        """
        pass


class MethodSequenceValidatingMixin:
    """Mixin for validating method sequences in executors."""
    
    def _validate_method_sequences(self) -> None:
        """Validate that all methods in the sequence exist and are callable.
        
        Raises:
            ValueError: If a class is not registered, method doesn't exist, or method is not callable
        """
        seq = self._get_method_sequence()
        for class_name, method_name in seq:
            instance = self.executor.instances.get(class_name)
            if instance is None:
                raise ValueError(f"Class {class_name} not in executor registry")
            if not hasattr(instance, method_name):
                raise ValueError(f"{class_name} has no method {method_name}")
            method = getattr(instance, method_name)
            if not callable(method):
                raise ValueError(f"{class_name}.{method_name} is not callable")
    
    def _get_method_sequence(self) -> list[tuple[str, str]]:
        """Return the method sequence for this executor.
        
        Section 5.1: Support METHOD_SEQUENCE class attribute (preferred)
        Falls back to _get_method_sequence() method for backward compatibility.
        
        Returns:
            List of (class_name, method_name) tuples
        """
        # Section 5.1: Check for METHOD_SEQUENCE class attribute first (new pattern)
        if hasattr(self.__class__, 'METHOD_SEQUENCE'):
            return self.__class__.METHOD_SEQUENCE
        # Fallback to method implementation for backward compatibility
        return []


class AdvancedDataFlowExecutor(ExecutorBase, MethodSequenceValidatingMixin):
    """Advanced executor with frontier paradigmatic capabilities"""
    
    # Calibration threshold: methods with scores below this are skipped
    CALIBRATION_SKIP_THRESHOLD = 0.3

    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        questionnaire_provider=None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,  # NEW
    ) -> None:
        # Section 3: ExecutorConfig Contract Enforcement
        # Config is REQUIRED - no fallbacks allowed
        if config is None:
            raise ValueError(
                f"{self.__class__.__name__}: ExecutorConfig is required and cannot be None. "
                "Use build_processor() factory or provide explicit config."
            )
        
        self.executor = method_executor
        self.signal_registry = signal_registry
        self.questionnaire_provider = questionnaire_provider
        self.config = config or CONSERVATIVE_CONFIG
        
        # NEW: Calibration orchestrator
        self.calibration = calibration_orchestrator
        
        # NEW: Store calibration results for current execution
        self.calibration_results: dict[str, "CalibrationResult"] = {}



        # Get advanced module configuration from config or use default
        # Pydantic ensures type safety, so if advanced_modules is set, it's AdvancedModuleConfig
        adv_config: AdvancedModuleConfig = (
            self.config.advanced_modules or CONSERVATIVE_ADVANCED_CONFIG
        )
    
    def _validate_executor_config(self) -> None:
        """Section 3.2: Validate config at construction time.
        
        Enforces contract requirements:
        - timeout_s > 0
        - retry >= 0
        - seed >= 0
        - Logs config hash for traceability
        """
        if self.config.timeout_s <= 0:
            raise ValueError(f"config.timeout_s must be > 0, got {self.config.timeout_s}")
        
        if self.config.retry < 0:
            raise ValueError(f"config.retry must be >= 0, got {self.config.retry}")
        
        if self.config.seed < 0:
            raise ValueError(f"config.seed must be >= 0, got {self.config.seed}")
        
        config_hash = self.config.compute_hash()
        logger.info(
            "executor_config_validated",
            extra={
                "executor_class": self.__class__.__name__,
                "config_hash": config_hash,
                "timeout_s": self.config.timeout_s,
                "retry": self.config.retry,
                "seed": self.config.seed,
            }
        )

        # Section 7.2: Track advanced module activation
        self.module_activations = {
            "quantum": {"count": 0, "total_time": 0.0},
            "neuromorphic": {"count": 0, "total_time": 0.0},
            "causal": {"count": 0, "total_time": 0.0},
            "info_theory": {"count": 0, "total_time": 0.0},
            "meta_learning": {"count": 0, "total_time": 0.0},
        }
        
        # Log only hard facts with academic basis
        logger.info(
            "executor_initialized",
            extra={
                "executor_class": self.__class__.__name__,
                "config_hash": self.config.compute_hash(),
                "timeout_s": self.config.timeout_s,
                "retry": self.config.retry,
                "advanced_modules": "academically_grounded",
                "advanced_module_version": adv_config.advanced_module_version,  # Section 7.3
                "quantum_methods": adv_config.quantum_num_methods,
                "neuromorphic_stages": adv_config.neuromorphic_num_stages,
                "causal_variables": adv_config.causal_num_variables,
                "calibration_enabled": self.calibration is not None,  # NEW
            },
        )

        # Initialize advanced modules with academically-informed parameters
        # Parameters combine VERIFIED academic principles with EMPIRICAL practical defaults
        # See advanced_module_config.py for honest categorization
        
        # Quantum-inspired optimization (Nielsen & Chuang 2010)
        # FORMULA-DERIVED: iterations â ânum_methods from Grover's algorithm
        # EMPIRICAL: num_methods chosen for policy analysis (not from paper)
        self.quantum_optimizer = QuantumExecutionOptimizer(
            num_methods=adv_config.quantum_num_methods
        )
        
        # Neuromorphic computing (Maass 1997)
        # VERIFIED: Paper discusses spiking neurons and STDP
        # EMPIRICAL: 8-12 stages range based on practice (not explicit in paper)
        self.neuromorphic_controller = NeuromorphicFlowController(
            num_stages=adv_config.neuromorphic_num_stages
        )
        
        # Causal inference (Spirtes et al. 2000; Pearl 2009)
        # VERIFIED: PC algorithm and independence testing (Î±=0.05)
        # EMPIRICAL: 10-30 variables for computational tractability (not explicit)
        self.causal_graph = CausalGraph(
            num_variables=adv_config.causal_num_variables
        )
        
        # Information-theoretic flow optimization (Shannon 1948; Cover & Thomas 2006)
        # FORMULA-DERIVED: logâ(N) stages from information theory
        # EMPIRICAL: Practical minimum samples
        self.info_optimizer = InformationFlowOptimizer(
            num_stages=adv_config.info_num_stages
        )
        
        # Meta-learning strategy (Thrun & Pratt 1998; Hospedales et al. 2021)
        # VERIFIED: Learning rate range 0.01-0.1 from Thrun & Pratt
        # EMPIRICAL: Number of strategies based on exploration-exploitation (not explicit)
        self.meta_learner = MetaLearningStrategy(
            num_strategies=adv_config.meta_num_strategies,
            epsilon=adv_config.meta_epsilon,
            learning_rate=adv_config.meta_learning_rate,
        )
        
        # Attention mechanism (Vaswani et al. 2017; Bahdanau et al. 2014)
        # CLARIFIED: Vaswani uses 64 as per-head dimension (with 8 heads, d_model=512)
        # EMPIRICAL: We use 64 as conservative total for resource-constrained scenarios
        self.attention = AttentionMechanism(
            embedding_dim=adv_config.attention_embedding_dim
        )
        
        # Topological data analysis (Carlsson 2009)
        # VERIFIED: Dimension 1 sufficient, <1000 points practical
        self.topology_analyzer = PersistentHomology()
        
        # Category theory and probabilistic programming
        # No parameterization needed - theoretical constructs
        self.category_executor = CategoryTheoryExecutor()
        self.probabilistic_executor = ProbabilisticExecutor()

        self.execution_metrics: dict[str, list[float]] = defaultdict(list)
        self.method_dependencies: dict[str, set] = {}
        self._argument_context: dict[str, Any] = {}
        self.used_signals: list[dict[str, Any]] = []  # Track signal usage
        # Validate early: no executor can be constructed with missing/placeholder calibration
        self._validate_method_sequences()
        self._validate_calibrations()

        # NOTE: Validation NOT called in base class because most executors
        # define method_sequence in execute(), not in _get_method_sequence().
        # Executors that want validation must call it explicitly in their __init__.
    
    def _get_policy_area_for_question(self, question_id: str) -> str:
        """
        Map question ID to policy area using injected questionnaire provider.
        
        This uses the provider's already-loaded data, avoiding direct file I/O
        and respecting the dependency injection architecture.
        
        Args:
            question_id: Question ID (e.g., "Q001", "Q031")
            
        Returns:
            Policy area code (e.g., "PA01", "PA02")
        """
        # Use injected provider if available
        if self.questionnaire_provider:
            try:
                return self.questionnaire_provider.get_policy_area_for_question(question_id)
            except Exception as e:
                logger.warning(
                    "provider_policy_area_lookup_failed",
                    question_id=question_id,
                    error=str(e),
                    fallback="PA01"
                )
        else:
            logger.warning(
                "no_questionnaire_provider",
                question_id=question_id,
                fallback="PA01"
            )
        
        # Fallback to PA01
        return "PA01"

    def _fetch_signals(self, policy_area: str = "fiscal") -> dict[str, Any] | None:
        """
        Fetch signals from registry for the given policy area.
        
        Adds OpenTelemetry span for observability. Signal registry is now required
        (explicit None allowed for graceful degradation, but absence is logged).
        
        Args:
            policy_area: Policy area to fetch signals for
            
        Returns:
            Signal pack data or None if unavailable (explicit None or missing)
        """
        # Explicit None check - signal_registry is required but can be explicitly None
        if self.signal_registry is None:
            logger.warning(
                f"Signal registry is explicitly None for {self.__class__.__name__}. "
                "Execution will proceed without signal enhancement, which may reduce analysis quality."
            )
            return None
        
        if HAS_OTEL and tracer:
            with tracer.start_as_current_span("signals.fetch") as span:
                span.set_attribute("policy_area", policy_area)
                fetch_start = time.time()
                
                signal_pack = self.signal_registry.get(policy_area)
                
                fetch_duration = time.time() - fetch_start
                span.set_attribute("fetch_duration_ms", fetch_duration * 1000)
                
                if signal_pack:
                    span.set_attribute("signal_version", signal_pack.version)
                    signal_hash = signal_pack.compute_hash()[:16]
                    span.set_attribute("signal_hash", signal_hash)
                    span.set_status(Status(StatusCode.OK))
                    
                    # Track usage with enhanced metadata
                    self.used_signals.append({
                        "version": signal_pack.version,
                        "policy_area": signal_pack.policy_area,
                        "hash": signal_pack.compute_hash(),
                        "hash_short": signal_hash,
                        "keys_used": signal_pack.get_keys_used(),
                        "timestamp_utc": time.time(),
                        "pattern_count": len(signal_pack.patterns) if hasattr(signal_pack, 'patterns') else 0,
                    })
                    
                    logger.info(
                        f"Fetched signals for {policy_area}: version={signal_pack.version}, "
                        f"hash={signal_hash}"
                    )
                    
                    # Sort patterns for determinism (stable ordering across runs)
                    patterns = sorted(signal_pack.patterns) if isinstance(signal_pack.patterns, list) else signal_pack.patterns
                    
                    return {
                        "patterns": patterns,  # Sorted for determinism
                        "indicators": signal_pack.indicators,
                        "regex": signal_pack.regex,
                        "verbs": signal_pack.verbs,
                        "entities": signal_pack.entities,
                        "thresholds": signal_pack.thresholds,
                    }
                else:
                    span.set_status(Status(StatusCode.ERROR, "Signal pack not found"))
                    logger.warning(f"No signals found for policy area: {policy_area}")
                    return None
        else:
            # No OpenTelemetry, fetch without span
            signal_pack = self.signal_registry.get(policy_area)
            if signal_pack:
                signal_hash = signal_pack.compute_hash()[:16]
                self.used_signals.append({
                    "version": signal_pack.version,
                    "policy_area": signal_pack.policy_area,
                    "hash": signal_pack.compute_hash(),
                    "hash_short": signal_hash,
                    "keys_used": signal_pack.get_keys_used(),
                    "timestamp_utc": time.time(),
                    "pattern_count": len(signal_pack.patterns) if hasattr(signal_pack, 'patterns') else 0,
                })
                
                # Sort patterns for determinism (stable ordering across runs)
                patterns = sorted(signal_pack.patterns) if isinstance(signal_pack.patterns, list) else signal_pack.patterns
                
                logger.info(
                    f"Fetched signals for {policy_area}: version={signal_pack.version}, "
                    f"hash={signal_hash}"
                )
                
                return {
                    "patterns": patterns,  # Sorted for determinism
                    "indicators": signal_pack.indicators,
                    "regex": signal_pack.regex,
                    "verbs": signal_pack.verbs,
                    "entities": signal_pack.entities,
                    "thresholds": signal_pack.thresholds,
                }
            
            # Log signal miss (requested but not found)
            logger.warning(
                f"Signal pack not found for policy_area='{policy_area}' in {self.__class__.__name__}. "
                "This may affect analysis quality."
            )
            return None

    def _validate_calibrations(self) -> None:
        """
        Ensure every (class, method) pair in this executor's method sequence
        has an explicit, non-default calibration entry appropriate for
        policy-document analysis.
        
        Also validates calibration version compatibility.
        """
        # Check calibration version compatibility first
        from .versions import check_version_compatibility
        try:
            check_version_compatibility(
                "calibration",
                CALIBRATION_VERSION,
                MINIMUM_SUPPORTED_VERSION
            )
        except ValueError as e:
            raise RuntimeError(
                f"Calibration version incompatibility in {self.__class__.__name__}: {e}"
            ) from e
        
        # Validate each method has calibration
        seq = getattr(self, "_get_method_sequence", lambda: [])()
        for class_name, method_name in seq:
            calib = resolve_calibration(class_name, method_name)
            if calib is None:
                raise RuntimeError(
                    f"Missing calibration for {class_name}.{method_name} "
                    f"in {self.__class__.__name__}"
                )
            if calib.is_default_like():
                raise RuntimeError(
                    f"Default/placeholder calibration not allowed for "
                    f"{class_name}.{method_name} in {self.__class__.__name__}"
                )
    
    def get_calibration_manifest_data(self) -> dict[str, Any]:
        """
        Get calibration information for verification manifest.
        
        Returns:
            Dictionary with calibration version, hash, method count, and missing methods
        """
        import hashlib
        
        seq = getattr(self, "_get_method_sequence", lambda: [])()
        methods_calibrated = []
        methods_missing = []
        
        for class_name, method_name in seq:
            calib = resolve_calibration(class_name, method_name, strict=False)
            if calib:
                methods_calibrated.append(f"{class_name}.{method_name}")
            else:
                methods_missing.append(f"{class_name}.{method_name}")
        
        # Compute hash of calibrated methods
        calibration_data = "".join(sorted(methods_calibrated)).encode()
        calibration_hash = hashlib.sha256(calibration_data).hexdigest()[:16]
        
        return {
            "version": CALIBRATION_VERSION,
            "hash": calibration_hash,
            "methods_calibrated": len(methods_calibrated),
            "methods_missing": methods_missing,
        }

    def execute_with_optimization(self, doc, method_executor,
                                  method_sequence: list[tuple[str, str]], 
                                  *, 
                                  policy_unit_id: str | None = None,
                                  correlation_id: str | None = None) -> dict[str, Any]:
        """Execute with advanced optimization strategies and deterministic seeding
        
        NOW INTEGRATED WITH CONTRACT INFRASTRUCTURE for reproducibility!

        Includes:
        - Signal fetching and usage tracking
        - OpenTelemetry instrumentation
        - Structured logging for debugging
        - Retry logic for transient failures
        - Execution time tracking
        - Failure metrics collection
        - **DETERMINISTIC EXECUTION** via policy_unit_id seeding
        - **Section 3.3**: Config values propagated to execution context
        """
        execution_start = time.time()
        self.executor = method_executor
        
        # ============================================================
        # CALIBRATION PHASE (NEW - inserted per corrected spec)
        # ============================================================
        calibration_results = {}
        skipped_methods = []
        
        if self.calibration is not None:
            logger.info("calibration_phase_start")
            
            # Build context for calibration
            try:
                from saaaaaa.core.calibration.data_structures import ContextTuple
                
                # Extract context information from doc
                question_id = getattr(doc, 'question_id', 'Q000')
                dimension_id = getattr(doc, 'dimension_id', 'DIM00')
                policy_area_id = getattr(doc, 'policy_area_id', 'PA00')
                unit_quality = getattr(doc, 'unit_quality', 0.75)
                
                context = ContextTuple(
                    question_id=question_id,
                    dimension=dimension_id,
                    policy_area=policy_area_id,
                    unit_quality=unit_quality
                )
                
                # Get PDT structure if available
                pdt_structure = getattr(doc, 'pdt_structure', None)
                
                # Calibrate each method in the sequence
                for class_name, method_name in method_sequence:
                    method_id = f"{class_name}.{method_name}"
                    method_version = "v1.0.0"  # Default version
                    
                    try:
                        # THIS IS THE CRITICAL CALL THAT WAS MISSING:
                        cal_result = self.calibration.calibrate(
                            method_id=method_id,
                            method_version=method_version,
                            context=context,
                            pdt_structure=pdt_structure,
                            graph_config=self.config.compute_hash() if hasattr(self.config, 'compute_hash') else None,
                            subgraph_id=f"{question_id}_{class_name}"
                        )
                        
                        calibration_results[method_id] = cal_result
                        
                        logger.info(
                            "method_calibrated",
                            extra={
                                "method": method_id,
                                "final_score": cal_result.final_score,
                                "class": class_name
                            }
                        )
                        
                    except Exception as e:
                        logger.error(
                            "calibration_failed",
                            extra={
                                "method": method_id,
                                "error": str(e)
                            },
                            exc_info=True
                        )
                        # Continue without calibration for this method
                
                logger.info(
                    "calibration_phase_complete",
                    extra={"num_calibrated": len(calibration_results)}
                )
                
            except Exception as e:
                logger.error(
                    "calibration_phase_error",
                    extra={"error": str(e)},
                    exc_info=True
                )
        else:
            logger.info("calibration_disabled", extra={"reason": "orchestrator_is_none"})
        
        # ============================================================
        # END CALIBRATION PHASE
        # ============================================================
        
        results = {}
        current_data = doc.raw_text
        
        # Section 3.3: Use config.timeout_s for execution timeout budget
        total_timeout_budget = self.config.timeout_s
        logger.info(
            "execution_started",
            extra={
                "executor_class": self.__class__.__name__,
                "timeout_budget_s": total_timeout_budget,
                "retry_limit": self.config.retry,
                "seed": self.config.seed,
                "num_methods": len(method_sequence),
            }
        )
        
        # Derive policy_unit_id from environment or doc if not provided
        if policy_unit_id is None:
            policy_unit_id = os.getenv("POLICY_UNIT_ID", "default-policy")
        if correlation_id is None:
            import uuid
            correlation_id = str(uuid.uuid4())

        # Start OpenTelemetry span for entire execution
        span_context = tracer.start_as_current_span("executor.execute") if HAS_OTEL and tracer else None
        
        try:
            if span_context:
                span = span_context.__enter__()
                span.set_attribute("num_methods", len(method_sequence))
                span.set_attribute("policy_unit_id", policy_unit_id)
                span.set_attribute("correlation_id", correlation_id)
            
            # DETERMINISTIC EXECUTION CONTEXT - makes all random operations reproducible!
            with deterministic(policy_unit_id, correlation_id) as seeds:
                # Create local RNG for deterministic random operations
                rng = np.random.default_rng(seeds.np)
                
                logger.info(f"Executing with DETERMINISTIC seeding: policy_unit_id={policy_unit_id}, "
                          f"correlation_id={correlation_id}, seed={seeds.py}")
                
                # Fetch signals at the beginning of execution
                # Get question_id for signal tracking (extract from doc or method_sequence)
                question_id = getattr(doc, 'question_id', None) or 'Q000'
                
                # Determine policy area for this question
                policy_area = self._get_policy_area_for_question(question_id)
                
                # Fetch signals and store for use during execution
                signals = self._fetch_signals(policy_area)
                
                # Initialize consumption proof tracker
                consumption_proof = None
                if signals:
                    consumption_proof = SignalConsumptionProof(
                        executor_id=self.__class__.__name__,
                        question_id=question_id,
                        policy_area=policy_area,
                    )
                    
                    if span_context:
                        span.set_attribute("signals.fetched", True)
                        span.set_attribute("signals.pattern_count", len(signals.get("patterns", [])))
                        span.set_attribute("signals.policy_area", policy_area)
                    
                    # Store signals in context for methods to access
                    self._argument_context['signals'] = signals
                    self._argument_context['consumption_proof'] = consumption_proof
                    
                    logger.info(f"Signals loaded: {len(signals.get('patterns', []))} patterns, "
                               f"{len(signals.get('indicators', []))} indicators, "
                               f"policy_area={policy_area}")
                    
                    # CRITICAL: Actually USE the signals for pattern matching
                    # This demonstrates real signal consumption
                    import re
                    text = current_data if isinstance(current_data, str) else str(current_data)
                    patterns_to_try = signals.get('patterns', [])[:50]  # Limit for performance
                    
                    for pattern in patterns_to_try:
                        try:
                            matches = re.findall(pattern, text, re.IGNORECASE)
                            for match in matches[:3]:  # Limit matches per pattern
                                consumption_proof.record_pattern_match(pattern, match)
                        except re.error:
                            # Invalid regex pattern, skip
                            pass
                    
                    logger.info(f"Signal consumption: {len(consumption_proof.consumed_patterns)} pattern matches recorded")
                elif span_context:
                    span.set_attribute("signals.fetched", False)

                strategy_idx = self.meta_learner.select_strategy()
                self.meta_learner.get_strategy_config(strategy_idx)

                method_names = [f"{cls}.{method}" for cls, method in method_sequence]
                self.attention.prioritize_methods(method_names, method_names[:3])

                logger.info(f"Starting execution with {len(method_sequence)} methods using strategy {strategy_idx}")

                total_entropy = 0.0

                self._reset_argument_context(doc)
                # Re-add signals after reset if available
                if signals:
                    self._argument_context['signals'] = signals

                # Section 5.3: Runtime sequence tracking
                executed_sequence = []
                
                for idx, (class_name, method_name) in enumerate(method_sequence):
                    method_key = f"{class_name}.{method_name}"
                    
                    # ============================================================
                    # METHOD SKIPPING BASED ON CALIBRATION (NEW)
                    # ============================================================
                    if method_key in calibration_results:
                        cal_score = calibration_results[method_key].final_score
                        
                        if cal_score < self.CALIBRATION_SKIP_THRESHOLD:
                            logger.warning(
                                "method_skipped_low_calibration",
                                extra={
                                    "method": method_key,
                                    "score": cal_score,
                                    "threshold": self.CALIBRATION_SKIP_THRESHOLD
                                }
                            )
                            
                            skipped_methods.append({
                                "method_id": method_key,
                                "calibration_score": cal_score,
                                "threshold": self.CALIBRATION_SKIP_THRESHOLD,
                                "reason": "calibration_score_below_threshold"
                            })
                            
                            continue  # SKIP THIS METHOD
                    # ============================================================
                    # END METHOD SKIPPING
                    # ============================================================
                    
                    executed_sequence.append((class_name, method_name))

                    self.probabilistic_executor.define_prior(
                        method_key, "beta", alpha=2, beta=2
                    )
                    self.probabilistic_executor.sample_prior(method_key)

                    # Execute with retry logic
                    method_start = time.time()
                    success = False
                    max_retries = 3
                    prepared_kwargs = {}  # Initialize to prevent UnboundLocalError in failure logging

                    for attempt in range(max_retries):
                        try:
                            prepared_kwargs = self._prepare_arguments(
                                class_name,
                                method_name,
                                doc,
                                current_data,
                            )

                            result = self.executor.execute(
                                class_name,
                                method_name,
                                **prepared_kwargs,
                            )

                            results[method_key] = result
                            success = True

                            self.info_optimizer.update_flow_metrics(idx, result)

                            data_quality = self._assess_data_quality(result)
                            self.neuromorphic_controller.process_data_flow([data_quality])

                            performance = data_quality
                            self.probabilistic_executor.bayesian_update(method_key, performance)

                            entropy = self.info_optimizer.calculate_entropy(result)
                            total_entropy += entropy

                            if result is not None:
                                current_data = result

                            self._update_argument_context(
                                method_key,
                                result,
                                class_name,
                                method_name,
                            )

                            break  # Success, exit retry loop

                        except Exception as e:
                            if attempt < max_retries - 1:
                                _global_metrics.record_retry()
                                logger.warning(
                                    f"Method {method_key} failed on attempt {attempt + 1}/{max_retries}: {str(e)}. Retrying...",
                                    exc_info=False
                                )
                                time.sleep(0.1 * (attempt + 1))  # Exponential backoff
                            else:
                                results[method_key] = None
                                logger.error(
                                    "Method %s failed",
                                    f"{class_name}.{method_name}",
                                    exc_info=True,
                                    extra={
                                        'method_key': f"{class_name}.{method_name}",
                                        'class_name': class_name,
                                        'method_name': method_name,
                                        'prepared_kwargs_keys': list(prepared_kwargs.keys()),
                                        'error_type': type(e).__name__,
                                        'error_details': str(e),
                                    }
                                )

                    # Record execution metrics
                    method_time = time.time() - method_start
                    _global_metrics.record_execution(success, method_time, method_key)

                avg_entropy = total_entropy / max(len(method_sequence), 1)
                reward = self._calculate_reward(avg_entropy)
                self.meta_learner.update_strategy_performance(strategy_idx, reward)

                bottlenecks = self.info_optimizer.get_information_bottlenecks()

                total_time = time.time() - execution_start
                logger.info(
                    f"Execution completed in {total_time:.3f}s: {_global_metrics.successful_executions}/{_global_metrics.total_executions} methods successful",
                    extra={
                        'total_time': total_time,
                        'avg_entropy': avg_entropy,
                        'bottlenecks': len(bottlenecks),
                        'strategy': strategy_idx,
                        'policy_unit_id': policy_unit_id,
                        'correlation_id': correlation_id,
                    }
                )

                # Add execution metrics to span
                if span_context:
                    span.set_attribute("execution_time_s", total_time)
                    span.set_attribute("successful_methods", _global_metrics.successful_executions)
                    span.set_attribute("total_methods", _global_metrics.total_executions)
                span.set_attribute("avg_entropy", avg_entropy)
                span.set_attribute("used_signals_count", len(self.used_signals))
                span.set_status(Status(StatusCode.OK))

            # Save consumption proof if signals were used
            if consumption_proof and consumption_proof.consumed_patterns:
                try:
                    from pathlib import Path
                    proof_dir = Path('artifacts/signal_proofs')
                    consumption_proof.save_to_file(proof_dir)
                    logger.info(
                        f"Consumption proof saved: {len(consumption_proof.consumed_patterns)} patterns, "
                        f"proof chain: {consumption_proof.proof_chain[-1][:16] if consumption_proof.proof_chain else 'none'}..."
                    )
                except Exception as e:
                    logger.warning(f"Failed to save consumption proof: {e}")
            
            result = {
                'modality': 'TYPE_A',
                'elements': self._extract(results),
                'raw': results,
                'confidence': float(self._argument_context.get('confidence', 0.0) or 0.0),
                'meta': {
                    'strategy': strategy_idx,
                    'avg_entropy': avg_entropy,
                    'bottlenecks': bottlenecks,
                    'confidence_intervals': self._get_confidence_intervals(method_sequence),
                    'execution_time': total_time,
                    'metrics_summary': _global_metrics.get_summary(),
                    'used_signals': self.used_signals,  # Add signal usage metadata
                    'consumption_proof': consumption_proof.get_consumption_proof() if consumption_proof else None,
                }
            }
            
            # ============================================================
            # ADD CALIBRATION RESULTS TO OUTPUT (NEW)
            # ============================================================
            if calibration_results:
                from datetime import datetime
                result["_calibration"] = {
                    "executed_at": datetime.utcnow().isoformat(),
                    "config_hash": self.calibration.config.compute_system_hash() if self.calibration and hasattr(self.calibration.config, 'compute_system_hash') else None,
                    "scores": {
                        method_id: {
                            "final_score": res.final_score,
                            "layer_breakdown": {
                                str(layer): score.score
                                for layer, score in res.layer_scores.items()
                            },
                            "linear_contribution": res.linear_contribution,
                            "interaction_contribution": res.interaction_contribution,
                            "config_hash": res.computation_metadata.get("config_hash"),
                        }
                        for method_id, res in calibration_results.items()
                    },
                    "skipped_methods": skipped_methods,
                    "total_methods_calibrated": len(calibration_results),
                    "total_methods_skipped": len(skipped_methods),
                }
            # ============================================================
            # END CALIBRATION RESULTS
            # ============================================================
            
            return result
            
        finally:
            if span_context:
                span_context.__exit__(None, None, None)
    
    def execute_chunk(self, chunk_doc, chunk_id: int):
        """
        Execute on single chunk with restricted scope.
        
        This method enables chunk-aware processing by executing only on the
        relevant chunk data, avoiding redundant full-document processing.
        
        Args:
            chunk_doc: PreprocessedDocument containing the chunk
            chunk_id: ID of the chunk to process
            
        Returns:
            Execution results scoped to the chunk
        """
        # Store chunk context for argument resolution
        self._current_chunk_id = chunk_id
        self._chunk_mode = True
        
        try:
            # Get method sequence for this executor
            method_sequence = self._get_method_sequence()
            
            # Filter methods based on chunk type if available
            if chunk_doc.chunks and chunk_id < len(chunk_doc.chunks):
                chunk_type = chunk_doc.chunks[chunk_id].chunk_type
                method_sequence = self._filter_methods_for_chunk(method_sequence, chunk_type)
            
            # Execute with chunk boundaries enforced
            return self.execute_with_optimization(
                chunk_doc,
                self.executor,
                method_sequence,
            )
        finally:
            # Clean up chunk context
            self._chunk_mode = False
            self._current_chunk_id = None
    
    def _filter_methods_for_chunk(
        self, 
        methods: list[tuple[str, str]], 
        chunk_type: str
    ) -> list[tuple[str, str]]:
        """
        Filter methods based on chunk type relevance.
        
        Args:
            methods: Full method sequence
            chunk_type: Type of chunk being processed
            
        Returns:
            Filtered method sequence relevant to chunk type
        """
        # Mapping of chunk types to relevant method patterns
        # This is a simplified version - full implementation would use
        # more sophisticated matching based on executor configuration
        CHUNK_METHOD_PATTERNS = {
            "diagnostic": ["baseline", "gap", "diagnostic", "problem"],
            "activity": ["activity", "intervention", "action", "program"],
            "indicator": ["metric", "indicator", "kpi", "measure"],
            "resource": ["budget", "financial", "resource", "funding"],
            "temporal": ["timeline", "temporal", "schedule", "phase"],
            "entity": ["entity", "responsible", "stakeholder", "actor"],
        }
        
        patterns = CHUNK_METHOD_PATTERNS.get(chunk_type, [])
        if not patterns:
            # No filtering if chunk type unknown
            return methods
        
        # Filter methods that match chunk type patterns
        filtered = []
        for class_name, method_name in methods:
            method_lower = method_name.lower()
            class_lower = class_name.lower()
            
            # Check if method or class name matches any pattern
            if any(pattern in method_lower or pattern in class_lower for pattern in patterns):
                filtered.append((class_name, method_name))
        
        # If filtering results in empty list, return original
        # (better to execute all than execute none)
        return filtered if filtered else methods

    def _assess_data_quality(self, data: Any) -> float:
        """Assess quality of data output"""
        if data is None:
            return 0.0

        entropy = self.info_optimizer.calculate_entropy(data)
        max_entropy = 8.0
        quality = min(entropy / max_entropy, 1.0)

        return quality

    def _calculate_reward(self, avg_entropy: float) -> float:
        """Calculate reward for meta-learning"""
        return min(avg_entropy / 8.0, 1.0)

    def _get_confidence_intervals(self, method_sequence: list[tuple[str, str]]) -> dict[str, tuple[float, float]]:
        """Get confidence intervals for all methods"""
        intervals = {}
        for class_name, method_name in method_sequence:
            method_key = f"{class_name}.{method_name}"
            intervals[method_key] = self.probabilistic_executor.get_credible_interval(method_key)
        return intervals

    @abstractmethod
    def _extract(self, results: dict) -> list:
        """Extract final results (to be implemented by subclasses)"""
        pass

    # ------------------------------------------------------------------
    # Argument mapping helpers
    # ------------------------------------------------------------------

    # ============================================================================
    # ENHANCED ARGUMENT RESOLUTION WITH GRAPH-AWARE INTELLIGENCE
    # ============================================================================

    def _reset_argument_context(self, doc: Any) -> None:
        """Enhanced context initialization with graph-aware tracking"""
        raw_text = getattr(doc, 'raw_text', '') or ''
        sentences = list(getattr(doc, 'sentences', []) or [])
        tables = list(getattr(doc, 'tables', []) or [])

        self._argument_context = {
            'doc': doc,
            'text': raw_text,
            'sentences': sentences,
            'tables': tables,
            'matches': [],
            'positions': [],
            'confidence': 0.0,
            'pattern_specificity': 0.8,
            'text_length': len(raw_text),
            # Enhanced: Graph-aware context
            'grafo': None,  # NetworkX DiGraph for causal analysis
            'graph_nodes': [],  # Tracked nodes from causal extraction
            'graph_edges': [],  # Tracked edges from causal extraction
            'statements': [],  # Policy statements for graph construction
            # Enhanced: Segmentation tracking
            'segments': None,  # Text segments for analysis
            'segment_metadata': {},  # Metadata about segmentation strategy
        }

        # Initialize policy processor context
        policy_processor = self.executor.instances.get('IndustrialPolicyProcessor')
        if policy_processor is not None:
            dimension, category, _ = self._derive_dimension_category(policy_processor)
            self._argument_context.setdefault('dimension', dimension)
            self._argument_context.setdefault('category', category)

    def _prepare_arguments(
        self,
        class_name: str,
        method_name: str,
        doc: Any,
        current_data: Any,
    ) -> dict[str, Any]:
        instance = self.executor.instances.get(class_name)
        if instance is None:
            return {}

        try:
            method = getattr(instance, method_name)
        except AttributeError:
            return {}

        signature = inspect.signature(method)
        prepared: dict[str, Any] = {}

        self._ingest_payload_for_context(current_data)

        for name, param in signature.parameters.items():
            if name == 'self':
                continue

            value = self._resolve_argument(
                name,
                class_name,
                method_name,
                doc,
                current_data,
                instance,
            )

            if value is _ARG_UNSET:
                if param.default is inspect._empty:
                    # Provide safe fallbacks for required params
                    value = self._fallback_for(
                        name,
                        class_name,
                        method_name,
                        instance,
                    )
                else:
                    continue

            prepared[name] = value

        return prepared

    def _resolve_argument(
        self,
        name: str,
        class_name: str,
        method_name: str,
        doc: Any,
        current_data: Any,
        instance: Any,
    ) -> Any:
        """Enhanced argument resolution with sophisticated graph and segment handling"""
        ctx = self._argument_context
        
        # ========================================================================
        # NEW: CHUNK-AWARE ARGUMENT RESOLUTION
        # ========================================================================
        
        # Check if in chunk mode
        if hasattr(self, '_chunk_mode') and self._chunk_mode:
            chunk_id = getattr(self, '_current_chunk_id', None)
            
            if chunk_id is not None and doc.chunks and chunk_id < len(doc.chunks):
                chunk = doc.chunks[chunk_id]
                
                # Provide chunk-scoped text
                if name in {'text', 'raw_text', 'document_text'}:
                    return chunk.text
                
                # Provide chunk-scoped sentences
                if name in {'sentences', 'relevant_sentences', 'sentence_list'}:
                    if chunk.sentences and doc.sentences:
                        return [doc.sentences[i] for i in chunk.sentences if i < len(doc.sentences)]
                    elif doc.sentences:
                        # Fallback: extract sentences whose offsets are within chunk boundaries
                        return [
                            s for s in doc.sentences
                            if hasattr(s, 'start') and hasattr(s, 'end')
                            and s.start >= chunk.start_pos and s.end <= chunk.end_pos
                        ]
                    return []
                
                # Provide chunk-scoped tables
                if name in {'tables', 'table_data', 'raw_tables'}:
                    if chunk.tables and doc.tables:
                        return [doc.tables[i] for i in chunk.tables if i < len(doc.tables)]
                    elif doc.tables:
                        # Fallback: extract tables whose offsets are within chunk boundaries
                        return [
                            t for t in doc.tables
                            if hasattr(t, 'start') and hasattr(t, 'end')
                            and t.start >= chunk.start_pos and t.end <= chunk.end_pos
                        ]
                    return []
                
                # Restrict window size to chunk boundaries
                if name in {'window_size', 'context_window'}:
                    max_window = chunk.end_pos - chunk.start_pos
                    # Get configured window size from instance config if available
                    requested = getattr(getattr(instance, 'config', None), 'context_window_chars', 400)
                    return min(requested, max_window)

        # ========================================================================
        # SIGNAL CHANNEL INTEGRATION - Inject signals into method arguments
        # ========================================================================
        
        signals = ctx.get('signals')
        if signals:
            # Inject signal patterns
            if name in {'patterns', 'fiscal_patterns', 'signal_patterns'}:
                return signals.get('patterns', [])
            
            # Inject indicators
            if name in {'indicators', 'signal_indicators'}:
                return signals.get('indicators', [])
            
            # Inject regex patterns
            if name in {'regex', 'regex_patterns', 'signal_regex'}:
                return signals.get('regex', [])
            
            # Inject verbs
            if name in {'verbs', 'signal_verbs'}:
                return signals.get('verbs', [])
            
            # Inject entities
            if name in {'entities', 'signal_entities'}:
                return signals.get('entities', [])
            
            # Inject thresholds
            if name in {'thresholds', 'signal_thresholds'}:
                return signals.get('thresholds', {})
            
            # Inject all signals as dict
            if name in {'signals', 'signal_pack'}:
                return signals

        # ========================================================================
        # STANDARD ARGUMENTS (existing implementation retained)
        # ========================================================================
        
        if name in {'data', 'payload', 'input_data'}:
            return current_data

        if name in {'doc', 'document', 'preprocessed_document'}:
            return doc

        if name in {'text', 'raw_text', 'document_text'}:
            return ctx.get('text')

        if name in {'sentences', 'relevant_sentences', 'sentence_list'}:
            return ctx.get('sentences')

        if name in {'tables', 'table_data', 'raw_tables'}:
            return ctx.get('tables')

        if name in {'metadata', 'document_metadata'}:
            return getattr(doc, 'metadata', {})

        if name in {'matches', 'match_list'}:
            return ctx.get('matches', [])

        if name in {'positions', 'match_positions'}:
            return ctx.get('positions', [])

        # ========================================================================
        # ENHANCED: SOPHISTICATED SEGMENTS RESOLUTION
        # ========================================================================
        
        if name in {'segments', 'text_segments', 'segment_list'}:
            segments = ctx.get('segments')
            
            if segments is not None:
                return segments
            
            # Strategy 1: Use sentences if available (most common case)
            sentences = ctx.get('sentences')
            if sentences and isinstance(sentences, list):
                ctx['segments'] = sentences
                ctx['segment_metadata'] = {
                    'strategy': 'sentence_based',
                    'count': len(sentences),
                    'source': 'context'
                }
                return sentences
            
            # Strategy 2: Intelligent text segmentation using semantic boundaries
            text = ctx.get('text', '')
            if text:
                # Split on paragraph boundaries first
                paragraphs = [p.strip() for p in text.split('\n\n') if p.strip()]
                
                if paragraphs:
                    segments = paragraphs
                else:
                    # Fallback: sentence-like splitting on period boundaries
                    segments = [s.strip() for s in text.split('.') if s.strip()]
                
                ctx['segments'] = segments
                ctx['segment_metadata'] = {
                    'strategy': 'semantic_split',
                    'count': len(segments),
                    'avg_length': sum(len(s) for s in segments) / max(len(segments), 1)
                }
                return segments
            
            # Strategy 3: Return empty list as safe fallback
            ctx['segments'] = []
            ctx['segment_metadata'] = {'strategy': 'empty_fallback'}
            return []

        # ========================================================================
        # ENHANCED: GRAPH OBJECT RESOLUTION (DiGraph for causal analysis)
        # ========================================================================
        
        if name in {'grafo', 'graph', 'causal_graph', 'dag'}:
            # Strategy 1: Return cached graph from context
            grafo = ctx.get('grafo')
            if grafo is not None:
                return grafo
            
            # Strategy 2: Check if instance has a graph attribute
            if hasattr(instance, 'grafo'):
                grafo = instance.grafo
                ctx['grafo'] = grafo
                return grafo
            
            if hasattr(instance, 'graph'):
                grafo = instance.graph
                ctx['grafo'] = grafo
                return grafo
            
            # Strategy 3: Construct graph from statements if available
            statements = ctx.get('statements')
            if statements:
                grafo = self._construct_causal_graph(statements, instance)
                if grafo is not None:
                    ctx['grafo'] = grafo
                    return grafo
            
            # Strategy 4: Return empty graph as standard fallback
            grafo = self._create_empty_graph()
            ctx['grafo'] = grafo
            return grafo

        # ========================================================================
        # ENHANCED: GRAPH NODE RESOLUTION (origen, destino for causal links)
        # ========================================================================
        
        if name in {'origen', 'source', 'source_node', 'from_node'}:
            # Strategy 1: Extract from current_data if it's a dict or tuple
            if isinstance(current_data, dict):
                if 'origen' in current_data:
                    return current_data['origen']
                if 'source' in current_data:
                    return current_data['source']
                if 'from' in current_data:
                    return current_data['from']
            
            # Strategy 2: Extract from tuple (common pattern: (origen, destino))
            if isinstance(current_data, tuple) and len(current_data) >= 2:
                return current_data[0]
            
            # Strategy 3: Infer from graph context (first node in recent edges)
            graph_edges = ctx.get('graph_edges', [])
            if graph_edges and isinstance(graph_edges[-1], (tuple, list)):
                return graph_edges[-1][0]
            
            # Strategy 4: Use first node from tracked nodes
            graph_nodes = ctx.get('graph_nodes', [])
            if graph_nodes:
                return graph_nodes[0]
            
            # Strategy 5: Return None (method will need to handle)
            return _ARG_UNSET
        
        if name in {'destino', 'target', 'target_node', 'to_node'}:
            # Strategy 1: Extract from current_data if it's a dict or tuple
            if isinstance(current_data, dict):
                if 'destino' in current_data:
                    return current_data['destino']
                if 'target' in current_data:
                    return current_data['target']
                if 'to' in current_data:
                    return current_data['to']
            
            # Strategy 2: Extract from tuple (common pattern: (origen, destino))
            if isinstance(current_data, tuple) and len(current_data) >= 2:
                return current_data[1]
            
            # Strategy 3: Infer from graph context (second node in recent edges)
            graph_edges = ctx.get('graph_edges', [])
            if graph_edges and isinstance(graph_edges[-1], (tuple, list)) and len(graph_edges[-1]) >= 2:
                return graph_edges[-1][1]
            
            # Strategy 4: Use second node from tracked nodes
            graph_nodes = ctx.get('graph_nodes', [])
            if len(graph_nodes) >= 2:
                return graph_nodes[1]
            
            # Strategy 5: Return None (method will need to handle)
            return _ARG_UNSET

        # ========================================================================
        # ENHANCED: STATEMENTS RESOLUTION (for graph construction)
        # ========================================================================
        
        if name in {'statements', 'policy_statements', 'causal_statements'}:
            statements = ctx.get('statements')
            
            if statements:
                return statements
            
            # Extract statements from current_data if it's a list
            if isinstance(current_data, list):
                ctx['statements'] = current_data
                return current_data
            
            # Use sentences as statements if available
            sentences = ctx.get('sentences')
            if sentences:
                ctx['statements'] = sentences
                return sentences
            
            return []

        # ========================================================================
        # EXISTING SOPHISTICATED RESOLUTIONS (all retained)
        # ========================================================================
        
        if name == 'match_position':
            positions = ctx.get('positions') or []
            if positions:
                return positions[0]
            matches = ctx.get('matches') or []
            if matches:
                index = ctx.get('text', '').find(matches[0])
                if index >= 0:
                    return index
            return 0

        if name == 'window_size':
            config = getattr(instance, 'config', None)
            return getattr(config, 'context_window_chars', 400)

        if name in {'pattern_specificity', 'specificity'}:
            matches = ctx.get('matches') or []
            return self._compute_pattern_specificity(matches)

        if name in {'total_corpus_size', 'text_length', 'corpus_size'}:
            length = ctx.get('text_length')
            if not length:
                sentences = ctx.get('sentences') or []
                length = sum(len(s) for s in sentences)
            return max(1, length)

        if name == 'confidence':
            return ctx.get('confidence', 0.0)

        if name in {'dimension', 'policy_dimension'}:
            dimension = ctx.get('dimension')
            if dimension is None:
                dimension, category, _ = self._derive_dimension_category(instance)
                ctx['dimension'] = dimension
                ctx.setdefault('category', category)
            return ctx.get('dimension')

        if name in {'category', 'policy_category'}:
            category = ctx.get('category')
            if category is None:
                dimension, category, _ = self._derive_dimension_category(instance)
                ctx.setdefault('dimension', dimension)
                ctx['category'] = category
            return ctx.get('category')

        if name == 'compiled_patterns':
            patterns = ctx.get('compiled_patterns')
            if patterns is None:
                patterns = self._extract_all_patterns(instance)
                ctx['compiled_patterns'] = patterns
            return patterns

        if name in {'pattern_registry', 'patterns'}:
            return getattr(instance, '_pattern_registry', {})

        if name in {'values', 'value_array'}:
            matches = ctx.get('matches') or []
            if matches:
                return np.array([len(m) for m in matches], dtype=float)
            return np.array([0.0], dtype=float)

        if name in {'positions_with_scores'}:
            matches = ctx.get('matches') or []
            positions = ctx.get('positions') or []
            return list(zip(positions, matches))

        if name in {'pattern_matches', 'match_metadata'}:
            return {
                'matches': ctx.get('matches', []),
                'positions': ctx.get('positions', []),
                'confidence': ctx.get('confidence', 0.0),
            }

        if name in {'doc_id', 'document_id'}:
            metadata = getattr(doc, 'metadata', {}) or {}
            return metadata.get('document_id') or getattr(doc, 'document_id', 'document_1')

        return _ARG_UNSET

    def _fallback_for(
        self,
        name: str,
        class_name: str,
        method_name: str,
        instance: Any,
    ) -> Any:
        """Enhanced fallback with sophisticated graph and segment handling"""
        ctx = self._argument_context

        # ========================================================================
        # ENHANCED: GRAPH AND NODE FALLBACKS
        # ========================================================================
        
        if name in {'grafo', 'graph', 'causal_graph', 'dag'}:
            # Import NetworkX for graph creation
            try:
                import networkx as nx
                # Create empty DiGraph as safe fallback
                grafo = nx.DiGraph()
                ctx['grafo'] = grafo
                logger.debug(f"Created empty DiGraph fallback for {class_name}.{method_name}")
                return grafo
            except ImportError:
                logger.warning("NetworkX not available, returning None for graph parameter")
                return None
        
        if name in {'origen', 'source', 'source_node', 'from_node'}:
            # Return a default node identifier
            return "node_0"
        
        if name in {'destino', 'target', 'target_node', 'to_node'}:
            # Return a default node identifier
            return "node_1"
        
        if name in {'statements', 'policy_statements', 'causal_statements'}:
            # Use sentences as statement fallback
            return ctx.get('sentences', [])

        # ========================================================================
        # ENHANCED: SEGMENTS FALLBACK
        # ========================================================================
        
        if name in {'segments', 'text_segments', 'segment_list'}:
            # Multi-strategy fallback
            sentences = ctx.get('sentences')
            if sentences:
                return sentences
            
            text = ctx.get('text', '')
            if text:
                # Intelligent paragraph segmentation
                segments = [p.strip() for p in text.split('\n\n') if p.strip()]
                if not segments:
                    segments = [s.strip() + '.' for s in text.split('.') if s.strip()]
                return segments
            
            return []

        # ========================================================================
        # EXISTING SOPHISTICATED FALLBACKS (all retained)
        # ========================================================================
        
        if name in {'matches', 'match_list'}:
            return []
        
        if name in {'positions', 'match_positions'}:
            return []
        
        if name == 'confidence':
            return 0.0
        
        if name == 'pattern_specificity':
            return ctx.get('pattern_specificity', 0.8)
        
        if name in {'total_corpus_size', 'text_length', 'corpus_size'}:
            return max(1, ctx.get('text_length') or 1)
        
        if name == 'compiled_patterns':
            patterns = self._extract_all_patterns(instance)
            ctx['compiled_patterns'] = patterns
            return patterns
        
        if name == 'relevant_sentences':
            return ctx.get('sentences', [])
        
        if name == 'window_size':
            config = getattr(instance, 'config', None)
            return getattr(config, 'context_window_chars', 400)
        
        if name == 'match_position':
            return 0
        
        if name in {'dimension', 'policy_dimension'}:
            dimension, category, _ = self._derive_dimension_category(instance)
            ctx.setdefault('category', category)
            ctx['dimension'] = dimension
            return dimension
        
        if name in {'category', 'policy_category'}:
            dimension, category, _ = self._derive_dimension_category(instance)
            ctx.setdefault('dimension', dimension)
            ctx['category'] = category
            return category
        
        if name in {'values', 'value_array'}:
            return np.array([0.0], dtype=float)

        if name in {'text', 'raw_text', 'document_text'}:
            return ctx.get('text', '')
        
        if name in {'sentences', 'sentence_list'}:
            return ctx.get('sentences', [])
        
        if name in {'tables', 'table_data'}:
            return ctx.get('tables', [])

        logger.debug(
            "No explicit argument mapping for required parameter '%s' on %s.%s; defaulting to None",
            name,
            class_name,
            method_name,
        )
        return None

    def _update_argument_context(
        self,
        method_key: str,
        result: Any,
        class_name: str,
        method_name: str,
    ) -> None:
        """Enhanced context update with graph-aware tracking"""
        ctx = self._argument_context

        # ========================================================================
        # ENHANCED: TRACK GRAPH OBJECTS FROM RESULTS
        # ========================================================================
        
        # Track DiGraph objects from causal methods
        if class_name == 'TeoriaCambio' and method_name == 'construir_grafo_causal':
            try:
                import networkx as nx
                if isinstance(result, nx.DiGraph):
                    ctx['grafo'] = result
                    ctx['graph_nodes'] = list(result.nodes())
                    ctx['graph_edges'] = list(result.edges())
                    logger.debug(f"Cached DiGraph with {len(ctx['graph_nodes'])} nodes, {len(ctx['graph_edges'])} edges")
            except ImportError:
                pass
        
        # Track statements from extraction methods
        if 'extract' in method_name.lower() and 'statement' in method_name.lower():
            if isinstance(result, list):
                ctx['statements'] = result
        
        # Track nodes and edges from causal extraction
        if class_name == 'CausalExtractor':
            if isinstance(result, dict):
                if 'nodes' in result:
                    ctx['graph_nodes'] = result['nodes']
                if 'edges' in result:
                    ctx['graph_edges'] = result['edges']
                if 'statements' in result:
                    ctx['statements'] = result['statements']

        # ========================================================================
        # ENHANCED: TRACK SEGMENTS FROM RESULTS
        # ========================================================================
        
        # Track segments from segmentation methods
        if 'segment' in method_name.lower():
            if isinstance(result, list) and all(isinstance(item, str) for item in result):
                ctx['segments'] = result
                ctx['segment_metadata'] = {
                    'strategy': 'method_result',
                    'method': method_key,
                    'count': len(result)
                }

        # ========================================================================
        # EXISTING SOPHISTICATED TRACKING (all retained)
        # ========================================================================
        
        # Track matches and positions from pattern matching
        if isinstance(result, tuple) and len(result) == 2:
            possible_matches, possible_positions = result
            if isinstance(possible_matches, list):
                ctx['matches'] = possible_matches
                ctx['pattern_specificity'] = self._compute_pattern_specificity(possible_matches)
            if isinstance(possible_positions, list):
                ctx['positions'] = possible_positions

        # Track sentences from sentence segmentation
        if isinstance(result, list) and all(isinstance(item, str) for item in result):
            ctx['sentences'] = result

        # Track various metrics from dict results
        if isinstance(result, dict):
            if 'matches' in result and isinstance(result['matches'], list):
                ctx['matches'] = result['matches']
                ctx['pattern_specificity'] = self._compute_pattern_specificity(result['matches'])
            if 'match_positions' in result and isinstance(result['match_positions'], list):
                ctx['positions'] = result['match_positions']
            if 'positions' in result and isinstance(result['positions'], list):
                ctx['positions'] = result['positions']
            if 'confidence' in result:
                try:
                    ctx['confidence'] = float(result['confidence'])
                except (TypeError, ValueError):
                    pass
            if 'dimension' in result:
                ctx['dimension'] = result['dimension']
            if 'category' in result:
                ctx['category'] = result['category']

        # Track confidence from evidence scoring
        if isinstance(result, (int, float)) and class_name == 'BayesianEvidenceScorer' and method_name == 'compute_evidence_score':
            ctx['confidence'] = float(result)

        # Update text length if sentences change
        if ctx.get('sentences') and not ctx.get('text_length'):
            ctx['text_length'] = sum(len(s) for s in ctx['sentences'])

    # ========================================================================
    # ENHANCED: GRAPH CONSTRUCTION HELPER
    # ========================================================================

    def _create_empty_graph(self):
        """Create an empty DiGraph for causal analysis.
        
        Raises:
            ImportError: If NetworkX is not available
        """
        try:
            import networkx as nx
        except ImportError as e:
            raise ImportError("NetworkX is required for graph operations") from e
        return nx.DiGraph()

    def _construct_causal_graph(self, statements: list, instance: Any) -> Any:
        """Construct causal graph from statements with sophisticated extraction"""
        grafo = self._create_empty_graph()
        
        # Extract potential causal relationships from statements
        causal_indicators = [
            'porque', 'ya que', 'debido a', 'causa', 'resultado',
            'therefore', 'because', 'due to', 'causes', 'results in',
            'conduce a', 'genera', 'produce', 'implica'
        ]
        
        nodes = []
        edges = []
        
        for idx, statement in enumerate(statements):
                if not isinstance(statement, str):
                    continue
                
                statement_lower = statement.lower()
                
                # Check if statement contains causal indicators
                has_causal = any(indicator in statement_lower for indicator in causal_indicators)
                
                if has_causal:
                    # Simple node extraction: split on causal words
                    for indicator in causal_indicators:
                        if indicator in statement_lower:
                            parts = statement_lower.split(indicator, 1)
                            if len(parts) == 2:
                                node_from = f"node_{len(nodes)}"
                                node_to = f"node_{len(nodes) + 1}"
                                nodes.extend([node_from, node_to])
                                edges.append((node_from, node_to))
                                break
                else:
                    # Add as isolated node
                    node_id = f"node_{len(nodes)}"
                    nodes.append(node_id)
        
        # Build graph
        grafo.add_nodes_from(set(nodes))
        grafo.add_edges_from(edges)
        
        logger.debug(f"Constructed causal graph with {len(grafo.nodes())} nodes, {len(grafo.edges())} edges")
        
        return grafo

    @staticmethod
    def _compute_pattern_specificity(matches: list[str]) -> float:
        if not matches:
            return 0.8
        uniqueness = len(set(matches))
        return min(0.95, max(0.2, uniqueness / max(1, len(matches))))

    @staticmethod
    def _extract_all_patterns(instance: Any) -> list[Any]:
        pattern_registry = getattr(instance, '_pattern_registry', {}) or {}
        compiled_patterns: list[Any] = []
        for categories in pattern_registry.values():
            compiled_patterns.extend(chain.from_iterable(categories.values()))
        return compiled_patterns

    @staticmethod
    def _derive_dimension_category(instance: Any) -> tuple[Any, str, list[Any]]:
        pattern_registry = getattr(instance, '_pattern_registry', {}) or {}
        dimension = getattr(instance, 'default_dimension', None)
        category = 'general'
        compiled_patterns: list[Any] = []

        if pattern_registry:
            dimension = next(iter(pattern_registry.keys()), dimension)
            categories = pattern_registry.get(dimension, {}) if dimension in pattern_registry else {}
            if categories:
                category = next(iter(categories.keys()), category)
                compiled_patterns = list(categories.get(category, []))

        if dimension is None:
            dimension = 'd1_insumos'

        return dimension, category, compiled_patterns

    # ------------------------------------------------------------------
    # Context enrichment utilities
    # ------------------------------------------------------------------

    def _ingest_payload_for_context(self, payload: Any) -> None:
        if payload is None:
            return

        ctx = self._argument_context

        grafo = self._extract_graph(payload)
        if grafo is not None and self._is_graph_like(grafo):
            ctx['grafo'] = grafo

        edge = self._extract_edge(payload)
        if edge is not None:
            ctx['current_edge'] = edge

        segments = self._extract_segments(payload)
        if segments is not None:
            ctx['segments'] = segments
            if not ctx.get('text_length') and isinstance(segments, list):
                text_lengths = [len(self._segment_to_text(seg)) for seg in segments]
                if any(text_lengths):
                    ctx['text_length'] = sum(text_lengths)

    def _resolve_edge_component(
        self,
        ctx: dict[str, Any],
        current_data: Any,
        *,
        index: int,
    ) -> Any:
        edge = ctx.get('current_edge')
        if isinstance(edge, tuple) and len(edge) > index:
            return edge[index]

        candidate = self._extract_edge(current_data)
        if candidate is not None and len(candidate) > index:
            ctx['current_edge'] = candidate
            return candidate[index]

        return None

    def _extract_edge(self, payload: Any) -> tuple[Any, Any] | None:
        if payload is None:
            return None

        origin = None
        destination = None

        if isinstance(payload, dict):
            origin = (
                payload.get('origen')
                or payload.get('source')
                or payload.get('source_node')
            )
            destination = (
                payload.get('destino')
                or payload.get('target')
                or payload.get('target_node')
            )
            if 'edge' in payload and isinstance(payload['edge'], (tuple, list)):
                edge = payload['edge']
                if len(edge) >= 2:
                    origin = origin or edge[0]
                    destination = destination or edge[1]

        elif isinstance(payload, (list, tuple)) and len(payload) >= 2:
            origin = payload[0]
            destination = payload[1]

        if origin is None or destination is None:
            return None

        return (
            self._coerce_categoria_causal(origin),
            self._coerce_categoria_causal(destination),
        )

    def _extract_segments(self, payload: Any) -> list[Any] | None:
        if payload is None:
            return None

        if isinstance(payload, dict):
            for key in ('segments', 'segmentos', 'segment_list'):
                value = payload.get(key)
                if isinstance(value, list) and value:
                    return value
        elif isinstance(payload, list) and payload:
            sample = payload[0]
            if isinstance(sample, (str, dict)):
                return payload

        return None

    def _extract_graph(self, payload: Any) -> Any:
        if self._is_graph_like(payload):
            return payload

        if isinstance(payload, dict):
            for value in payload.values():
                if self._is_graph_like(value):
                    return value

        return None

    @staticmethod
    def _is_graph_like(obj: Any) -> bool:
        if obj is None:
            return False
        if nx is not None and isinstance(obj, nx.DiGraph):
            return True
        return hasattr(obj, 'nodes') and hasattr(obj, 'edges')

    def _segment_to_text(self, segment: Any) -> str:
        if isinstance(segment, str):
            return segment
        if isinstance(segment, dict):
            for key in ('text', 'segment', 'content'):
                value = segment.get(key)
                if isinstance(value, str):
                    return value
        return ''

    @staticmethod
    def _coerce_categoria_causal(value: Any) -> Any:
        if CategoriaCausal is None or value is None:
            return value
        if isinstance(value, CategoriaCausal):
            return value
        if isinstance(value, str):
            normalized = value.strip().upper()
            if normalized in CategoriaCausal.__members__:
                return CategoriaCausal[normalized]
        return value

# ============================================================================
# ALL 30 EXECUTORS COMPLETE IMPLEMENTATION
# ============================================================================

class D1Q1_Executor(AdvancedDataFlowExecutor):
    """D1-Q1: LÃ­neas Base y Brechas Cuantificadas"""
    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        # Validate method sequence at construction time
        self._validate_method_sequences()
        self._validate_calibrations()
    
    def _get_method_sequence(self) -> list[tuple[str, str]]:
        """Return method sequence for this executor."""
        return [
            ('IndustrialPolicyProcessor', 'process'),
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_construct_evidence_bundle'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('BayesianEvidenceScorer', '_calculate_shannon_entropy'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PolicyContradictionDetector', '_statistical_significance_test'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('SemanticAnalyzer', '_calculate_semantic_complexity'),
            ('SemanticAnalyzer', '_classify_policy_domain'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
            ('BayesianNumericalAnalyzer', '_classify_evidence_strength'),
        ]

    def execute(self, doc, method_executor):
        method_sequence = self._get_method_sequence()
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D1Q2_Executor(AdvancedDataFlowExecutor):
    """D1-Q2: NormalizaciÃ³n y Fuentes"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_compile_pattern_registry'),
            ('PolicyTextProcessor', 'normalize_unicode'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PolicyAnalysisEmbedder', '_extract_numerical_values'),
            ('BayesianNumericalAnalyzer', '_compute_coherence'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D1Q3_Executor(AdvancedDataFlowExecutor):
    """D1-Q3: AsignaciÃ³n de Recursos"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('IndustrialPolicyProcessor', '_extract_point_evidence'),
            ('IndustrialPolicyProcessor', '_construct_evidence_bundle'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_extract_resource_mentions'),
            ('PolicyContradictionDetector', '_detect_numerical_inconsistencies'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('PolicyContradictionDetector', '_detect_resource_conflicts'),
            ('PolicyContradictionDetector', '_are_conflicting_allocations'),
            ('PolicyContradictionDetector', '_statistical_significance_test'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('TemporalLogicVerifier', '_extract_resources'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_extract_financial_amounts'),
            ('PDETMunicipalPlanAnalyzer', '_identify_funding_source'),
            ('PDETMunicipalPlanAnalyzer', '_analyze_funding_sources'),
            ('FinancialAuditor', 'trace_financial_allocation'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
            ('BayesianNumericalAnalyzer', 'compare_policies'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D1Q4_Executor(AdvancedDataFlowExecutor):
    """D1-Q4: Capacidad Institucional"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_build_point_patterns'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_calculate_graph_fragmentation'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_calculate_syntactic_complexity'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('SemanticAnalyzer', '_classify_value_chain_link'),
            ('PerformanceAnalyzer', '_detect_bottlenecks'),
            ('TextMiningEngine', '_identify_critical_links'),
            ('PDETMunicipalPlanAnalyzer', 'identify_responsible_entities'),
            ('PDETMunicipalPlanAnalyzer', '_classify_entity_type'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D1Q5_Executor(AdvancedDataFlowExecutor):
    """D1-Q5: Restricciones Temporales"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_detect_temporal_conflicts'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('TemporalLogicVerifier', 'verify_temporal_consistency'),
            ('TemporalLogicVerifier', '_build_timeline'),
            ('TemporalLogicVerifier', '_parse_temporal_marker'),
            ('TemporalLogicVerifier', '_has_temporal_conflict'),
            ('TemporalLogicVerifier', '_check_deadline_constraints'),
            ('TemporalLogicVerifier', '_classify_temporal_type'),
            ('SemanticAnalyzer', '_calculate_semantic_complexity'),
            ('PerformanceAnalyzer', '_calculate_throughput_metrics'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D2Q1_Executor(AdvancedDataFlowExecutor):
    """D2-Q1: Formato Tabular y Trazabilidad"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_clean_dataframe'),
            ('PDETMunicipalPlanAnalyzer', '_is_likely_header'),
            ('PDETMunicipalPlanAnalyzer', '_deduplicate_tables'),
            ('PDETMunicipalPlanAnalyzer', '_reconstruct_fragmented_tables'),
            ('PDETMunicipalPlanAnalyzer', '_classify_tables'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_municipal_plan'),
            ('PDETMunicipalPlanAnalyzer', '_extract_from_budget_table'),
            ('PDETMunicipalPlanAnalyzer', '_extract_from_responsibility_tables'),
            ('PDETMunicipalPlanAnalyzer', 'identify_responsible_entities'),
            ('PDETMunicipalPlanAnalyzer', '_consolidate_entities'),
            ('PDETMunicipalPlanAnalyzer', '_score_entity_specificity'),
            ('TemporalLogicVerifier', '_build_timeline'),
            ('TemporalLogicVerifier', '_check_deadline_constraints'),
            ('PolicyContradictionDetector', '_detect_temporal_conflicts'),
            ('SemanticProcessor', '_detect_table'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D2Q2_Executor(AdvancedDataFlowExecutor):
    """D2-Q2: Causalidad de Actividades"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_determine_relation_type'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_extract_policy_statements'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('CausalExtractor', '_extract_goals'),
            ('CausalExtractor', '_extract_goal_text'),
            ('CausalExtractor', '_classify_goal_type'),
            ('CausalExtractor', '_add_node_to_graph'),
            ('CausalExtractor', '_extract_causal_links'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('TextMiningEngine', 'diagnose_critical_links'),
            ('TextMiningEngine', '_analyze_link_text'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D2Q3_Executor(AdvancedDataFlowExecutor):
    """D2-Q3: Responsables de Actividades"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PDETMunicipalPlanAnalyzer', 'identify_responsible_entities'),
            ('PDETMunicipalPlanAnalyzer', '_extract_from_responsibility_tables'),
            ('PDETMunicipalPlanAnalyzer', '_consolidate_entities'),
            ('PDETMunicipalPlanAnalyzer', '_classify_entity_type'),
            ('PDETMunicipalPlanAnalyzer', '_score_entity_specificity'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_clean_dataframe'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyAnalysisEmbedder', 'semantic_search'),
            ('SemanticAnalyzer', '_classify_policy_domain'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D2Q4_Executor(AdvancedDataFlowExecutor):
    """D2-Q4: CuantificaciÃ³n de Actividades"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_extract_financial_amounts'),
            ('PDETMunicipalPlanAnalyzer', '_extract_from_budget_table'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_municipal_plan'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_extract_resource_mentions'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('PolicyContradictionDetector', '_detect_numerical_inconsistencies'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D2Q5_Executor(AdvancedDataFlowExecutor):
    """D2-Q5: EslabÃ³n Causal DiagnÃ³stico-Actividades"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_determine_relation_type'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_extract_policy_statements'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('TeoriaCambio', '_encontrar_caminos_completos'),
            ('TextMiningEngine', 'diagnose_critical_links'),
            ('TextMiningEngine', '_analyze_link_text'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D3Q1_Executor(AdvancedDataFlowExecutor):
    """D3-Q1: Indicadores de Producto"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('IndustrialPolicyProcessor', '_construct_evidence_bundle'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_indicator_to_dict'),
            ('PDETMunicipalPlanAnalyzer', '_find_product_mentions'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_municipal_plan'),
            ('PDETMunicipalPlanAnalyzer', '_classify_tables'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
            ('PolicyAnalysisEmbedder', '_extract_numerical_values'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D3Q2_Executor(AdvancedDataFlowExecutor):
    """D3-Q2: CuantificaciÃ³n de Productos"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_extract_financial_amounts'),
            ('PDETMunicipalPlanAnalyzer', '_extract_from_budget_table'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_municipal_plan'),
            ('PDETMunicipalPlanAnalyzer', '_find_product_mentions'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_extract_resource_mentions'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('PolicyContradictionDetector', '_detect_numerical_inconsistencies'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D3Q3_Executor(AdvancedDataFlowExecutor):
    """D3-Q3: Responsables de Productos"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PDETMunicipalPlanAnalyzer', 'identify_responsible_entities'),
            ('PDETMunicipalPlanAnalyzer', '_extract_from_responsibility_tables'),
            ('PDETMunicipalPlanAnalyzer', '_consolidate_entities'),
            ('PDETMunicipalPlanAnalyzer', '_classify_entity_type'),
            ('PDETMunicipalPlanAnalyzer', '_score_entity_specificity'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyAnalysisEmbedder', 'semantic_search'),
            ('SemanticAnalyzer', '_classify_policy_domain'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D3Q4_Executor(AdvancedDataFlowExecutor):
    """D3-Q4: Plazos de Productos"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('TemporalLogicVerifier', 'verify_temporal_consistency'),
            ('TemporalLogicVerifier', '_check_deadline_constraints'),
            ('TemporalLogicVerifier', '_classify_temporal_type'),
            ('TemporalLogicVerifier', '_build_timeline'),
            ('TemporalLogicVerifier', '_parse_temporal_marker'),
            ('TemporalLogicVerifier', '_has_temporal_conflict'),
            ('TemporalLogicVerifier', '_extract_resources'),
            ('PolicyContradictionDetector', '_detect_resource_conflicts'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PerformanceAnalyzer', '_calculate_throughput_metrics'),
            ('PerformanceAnalyzer', '_detect_bottlenecks'),
            ('TextMiningEngine', '_assess_risks'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D3Q5_Executor(AdvancedDataFlowExecutor):
    """D3-Q5: EslabÃ³n Causal Producto-Resultado"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_determine_relation_type'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_extract_policy_statements'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('CausalExtractor', '_extract_causal_links'),
            ('CausalExtractor', '_extract_causal_justifications'),
            ('CausalExtractor', '_calculate_confidence'),
            ('MechanismPartExtractor', 'extract_entity_activity'),
            ('MechanismPartExtractor', '_find_subject_entity'),
            ('MechanismPartExtractor', '_find_action_verb'),
            ('MechanismPartExtractor', '_validate_entity_activity'),
            ('MechanismPartExtractor', '_calculate_ea_confidence'),
            ('BayesianMechanismInference', 'infer_mechanisms'),
            ('BayesianMechanismInference', '_build_transition_matrix'),
            ('BayesianMechanismInference', '_infer_activity_sequence'),
            ('BayesianMechanismInference', '_test_necessity'),
            ('BayesianMechanismInference', '_test_sufficiency'),
            ('BayesianMechanismInference', '_classify_mechanism_type'),
            ('BeachEvidentialTest', 'apply_test_logic'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('TeoriaCambio', '_encontrar_caminos_completos'),
            ('TextMiningEngine', 'diagnose_critical_links'),
            ('TextMiningEngine', '_analyze_link_text'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D4Q1_Executor(AdvancedDataFlowExecutor):
    """D4-Q1: Indicadores de Resultado"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('IndustrialPolicyProcessor', '_construct_evidence_bundle'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_indicator_to_dict'),
            ('PDETMunicipalPlanAnalyzer', '_find_outcome_mentions'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_municipal_plan'),
            ('PDETMunicipalPlanAnalyzer', '_classify_tables'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
            ('PolicyAnalysisEmbedder', '_extract_numerical_values'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D4Q2_Executor(AdvancedDataFlowExecutor):
    """D4-Q2: Cadena Causal y Supuestos"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_extract_policy_statements'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('PolicyContradictionDetector', '_calculate_syntactic_complexity'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('CausalExtractor', '_extract_causal_links'),
            ('BayesianMechanismInference', 'infer_mechanisms'),
            ('BayesianMechanismInference', '_test_necessity'),
            ('BayesianMechanismInference', '_test_sufficiency'),
            ('BeachEvidentialTest', 'classify_test'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('TeoriaCambio', 'validacion_completa'),
            ('TeoriaCambio', '_validar_orden_causal'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D4Q3_Executor(AdvancedDataFlowExecutor):
    """D4-Q3: JustificaciÃ³n de AmbiciÃ³n"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', 'process'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('BayesianEvidenceScorer', '_calculate_shannon_entropy'),
            ('PolicyContradictionDetector', '_detect_numerical_inconsistencies'),
            ('PolicyContradictionDetector', '_calculate_objective_alignment'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('PolicyContradictionDetector', '_statistical_significance_test'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_extract_resource_mentions'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PDETMunicipalPlanAnalyzer', 'generate_recommendations'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_financial_feasibility'),
            ('PDETMunicipalPlanAnalyzer', '_assess_financial_sustainability'),
            ('PDETMunicipalPlanAnalyzer', '_bayesian_risk_inference'),
            ('FinancialAuditor', '_calculate_sufficiency'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
            ('BayesianNumericalAnalyzer', 'compare_policies'),
            ('BayesianNumericalAnalyzer', '_classify_evidence_strength'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D4Q4_Executor(AdvancedDataFlowExecutor):
    """D4-Q4: PoblaciÃ³n Objetivo"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('SemanticAnalyzer', '_classify_cross_cutting_themes'),
            ('SemanticAnalyzer', '_classify_policy_domain'),
            ('SemanticAnalyzer', 'extract_semantic_cube'),
            ('PolicyAnalysisEmbedder', 'semantic_search'),
            ('PolicyAnalysisEmbedder', '_filter_by_pdq'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D4Q5_Executor(AdvancedDataFlowExecutor):
    """D4-Q5: AlineaciÃ³n con Objetivos Superiores"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_calculate_objective_alignment'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('SemanticAnalyzer', '_classify_cross_cutting_themes'),
            ('SemanticAnalyzer', '_classify_policy_domain'),
            ('SemanticAnalyzer', 'extract_semantic_cube'),
            ('PolicyAnalysisEmbedder', 'semantic_search'),
            ('PolicyAnalysisEmbedder', 'compare_policy_interventions'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D5Q1_Executor(AdvancedDataFlowExecutor):
    """D5-Q1: Indicadores de Impacto"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('IndustrialPolicyProcessor', '_construct_evidence_bundle'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PDETMunicipalPlanAnalyzer', '_indicator_to_dict'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_municipal_plan'),
            ('PDETMunicipalPlanAnalyzer', '_classify_tables'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D5Q2_Executor(AdvancedDataFlowExecutor):
    """D5-Q2: EslabÃ³n Causal Resultado-Impacto"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_determine_relation_type'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_extract_policy_statements'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('CausalExtractor', '_extract_causal_links'),
            ('CausalExtractor', '_extract_causal_justifications'),
            ('BayesianMechanismInference', 'infer_mechanisms'),
            ('BayesianMechanismInference', '_test_necessity'),
            ('BayesianMechanismInference', '_test_sufficiency'),
            ('BayesianMechanismInference', '_classify_mechanism_type'),
            ('BeachEvidentialTest', 'apply_test_logic'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('TeoriaCambio', '_encontrar_caminos_completos'),
            ('TextMiningEngine', 'diagnose_critical_links'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D5Q3_Executor(AdvancedDataFlowExecutor):
    """D5-Q3: Evidencia de Causalidad"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_extract_quantitative_claims'),
            ('PolicyContradictionDetector', '_parse_number'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PolicyContradictionDetector', '_statistical_significance_test'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('CausalExtractor', '_extract_causal_justifications'),
            ('BayesianMechanismInference', 'infer_mechanisms'),
            ('BayesianMechanismInference', '_test_necessity'),
            ('BayesianMechanismInference', '_test_sufficiency'),
            ('BayesianNumericalAnalyzer', 'evaluate_policy_metric'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D5Q4_Executor(AdvancedDataFlowExecutor):
    """D5-Q4: Plazos de Impacto"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('TemporalLogicVerifier', 'verify_temporal_consistency'),
            ('TemporalLogicVerifier', '_check_deadline_constraints'),
            ('TemporalLogicVerifier', '_classify_temporal_type'),
            ('TemporalLogicVerifier', '_build_timeline'),
            ('TemporalLogicVerifier', '_parse_temporal_marker'),
            ('TemporalLogicVerifier', '_has_temporal_conflict'),
            ('PolicyContradictionDetector', '_extract_temporal_markers'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PerformanceAnalyzer', '_calculate_throughput_metrics'),
            ('PerformanceAnalyzer', '_detect_bottlenecks'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D5Q5_Executor(AdvancedDataFlowExecutor):
    """D5-Q5: Sostenibilidad Financiera"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PDETMunicipalPlanAnalyzer', 'analyze_financial_feasibility'),
            ('PDETMunicipalPlanAnalyzer', '_assess_financial_sustainability'),
            ('PDETMunicipalPlanAnalyzer', '_bayesian_risk_inference'),
            ('PDETMunicipalPlanAnalyzer', '_analyze_funding_sources'),
            ('PDETMunicipalPlanAnalyzer', 'extract_tables'),
            ('PolicyContradictionDetector', '_extract_resource_mentions'),
            ('PolicyContradictionDetector', '_detect_resource_conflicts'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('FinancialAuditor', 'trace_financial_allocation'),
            ('FinancialAuditor', '_calculate_sufficiency'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D6Q1_Executor(AdvancedDataFlowExecutor):
    """D6-Q1: Integridad de TeorÃ­a de Cambio"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_analyze_causal_dimensions'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('TeoriaCambio', 'validacion_completa'),
            ('TeoriaCambio', '_encontrar_caminos_completos'),
            ('TeoriaCambio', '_validar_orden_causal'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('AdvancedDAGValidator', 'calculate_acyclicity_pvalue'),
            ('AdvancedDAGValidator', '_calculate_statistical_power'),
            ('AdvancedDAGValidator', '_calculate_bayesian_posterior'),
            ('AdvancedDAGValidator', '_perform_sensitivity_analysis_internal'),
            ('AdvancedDAGValidator', 'get_graph_stats'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_get_graph_statistics'),
            ('PolicyContradictionDetector', '_calculate_graph_fragmentation'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('CausalExtractor', 'extract_causal_hierarchy'),
            ('OperationalizationAuditor', 'audit_evidence_traceability'),
            ('OperationalizationAuditor', '_audit_systemic_risk'),
            ('OperationalizationAuditor', 'bayesian_counterfactual_audit'),
            ('OperationalizationAuditor', '_generate_optimal_remediations'),
            ('CDAFFramework', 'process_document'),
            ('CDAFFramework', '_audit_causal_coherence'),
            ('CDAFFramework', '_validate_dnp_compliance'),
            ('CDAFFramework', '_generate_extraction_report'),
            ('PDETMunicipalPlanAnalyzer', 'construct_causal_dag'),
            ('PDETMunicipalPlanAnalyzer', '_identify_causal_nodes'),
            ('PDETMunicipalPlanAnalyzer', '_identify_causal_edges'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D6Q2_Executor(AdvancedDataFlowExecutor):
    """D6-Q2: Proporcionalidad y Continuidad (Anti-Milagro)"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', '_compile_pattern_registry'),
            ('IndustrialPolicyProcessor', '_build_point_patterns'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_calculate_syntactic_complexity'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_get_dependency_depth'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_determine_relation_type'),
            ('PolicyContradictionDetector', '_calculate_numerical_divergence'),
            ('PolicyContradictionDetector', '_statistical_significance_test'),
            ('PolicyContradictionDetector', '_detect_numerical_inconsistencies'),
            ('PolicyContradictionDetector', '_are_comparable_claims'),
            ('PolicyContradictionDetector', '_calculate_confidence_interval'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('TeoriaCambio', 'validacion_completa'),
            ('TeoriaCambio', '_encontrar_caminos_completos'),
            ('TeoriaCambio', '_validar_orden_causal'),
            ('AdvancedDAGValidator', 'calculate_acyclicity_pvalue'),
            ('AdvancedDAGValidator', '_calculate_statistical_power'),
            ('AdvancedDAGValidator', '_calculate_bayesian_posterior'),
            ('BeachEvidentialTest', 'classify_test'),
            ('BeachEvidentialTest', 'apply_test_logic'),
            ('BayesianMechanismInference', '_test_necessity'),
            ('BayesianMechanismInference', '_test_sufficiency'),
            ('BayesianMechanismInference', '_build_transition_matrix'),
            ('BayesianMechanismInference', '_calculate_type_transition_prior'),
            ('BayesianMechanismInference', '_infer_activity_sequence'),
            ('BayesianMechanismInference', '_aggregate_bayesian_confidence'),
            ('CausalInferenceSetup', 'classify_goal_dynamics'),
            ('CausalInferenceSetup', 'identify_failure_points'),
            ('CausalInferenceSetup', 'assign_probative_value'),
            ('CausalInferenceSetup', '_get_dynamics_pattern'),
            ('OperationalizationAuditor', '_audit_systemic_risk'),
            ('OperationalizationAuditor', 'bayesian_counterfactual_audit'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D6Q3_Executor(AdvancedDataFlowExecutor):
    """D6-Q3: Inconsistencias (Sistema Bicameral - Ruta 1)"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_detect_logical_incompatibilities'),
            ('PolicyContradictionDetector', 'detect'),
            ('PolicyContradictionDetector', '_detect_semantic_contradictions'),
            ('PolicyContradictionDetector', '_detect_numerical_inconsistencies'),
            ('PolicyContradictionDetector', '_detect_temporal_conflicts'),
            ('PolicyContradictionDetector', '_detect_resource_conflicts'),
            ('PolicyContradictionDetector', '_classify_contradiction'),
            ('PolicyContradictionDetector', '_calculate_severity'),
            ('PolicyContradictionDetector', '_generate_resolution_recommendations'),
            ('PolicyContradictionDetector', '_suggest_resolutions'),
            ('PolicyContradictionDetector', '_calculate_contradiction_entropy'),
            ('PolicyContradictionDetector', '_get_domain_weight'),
            ('PolicyContradictionDetector', '_has_logical_conflict'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('TextMiningEngine', 'diagnose_critical_links'),
            ('TextMiningEngine', '_identify_critical_links'),
            ('TeoriaCambio', 'validacion_completa'),
            ('TeoriaCambio', '_validar_orden_causal'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D6Q4_Executor(AdvancedDataFlowExecutor):
    """D6-Q4: AdaptaciÃ³n (Sistema Bicameral - Ruta 2)"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('TeoriaCambio', 'validacion_completa'),
            ('TeoriaCambio', '_validar_orden_causal'),
            ('TeoriaCambio', '_encontrar_caminos_completos'),
            ('TeoriaCambio', '_generar_sugerencias_internas'),
            ('TeoriaCambio', '_execute_generar_sugerencias_internas'),
            ('TeoriaCambio', '_extraer_categorias'),
            ('TeoriaCambio', '_es_conexion_valida'),
            ('TeoriaCambio', 'construir_grafo_causal'),
            ('AdvancedDAGValidator', 'calculate_acyclicity_pvalue'),
            ('AdvancedDAGValidator', '_perform_sensitivity_analysis_internal'),
            ('AdvancedDAGValidator', '_calculate_confidence_interval'),
            ('AdvancedDAGValidator', 'get_graph_stats'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('PolicyContradictionDetector', '_get_graph_statistics'),
            ('PolicyContradictionDetector', '_calculate_graph_fragmentation'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('PerformanceAnalyzer', '_generate_recommendations'),
            ('TextMiningEngine', '_generate_interventions'),
            ('CDAFFramework', '_validate_dnp_compliance'),
            ('CDAFFramework', '_generate_extraction_report'),
            ('CDAFFramework', '_generate_causal_model_json'),
            ('CDAFFramework', '_generate_dnp_compliance_report'),
            ('OperationalizationAuditor', 'audit_evidence_traceability'),
            ('OperationalizationAuditor', '_perform_counterfactual_budget_check'),
            ('FinancialAuditor', 'trace_financial_allocation'),
            ('FinancialAuditor', '_match_goal_to_budget'),
            ('FinancialAuditor', '_calculate_sufficiency'),
            ('FinancialAuditor', '_detect_allocation_gaps'),
            ('MechanismTypeConfig', 'check_sum_to_one'),
            ('PDETMunicipalPlanAnalyzer', 'generate_recommendations'),
            ('PDETMunicipalPlanAnalyzer', '_generate_optimal_remediations'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

class D6Q5_Executor(AdvancedDataFlowExecutor):
    """D6-Q5: ContextualizaciÃ³n y Enfoque Diferencial"""

    
    def __init__(
        self,
        method_executor,
        signal_registry=None,
        config: ExecutorConfig | None = None,
        calibration_orchestrator: "CalibrationOrchestrator | None" = None,
    ) -> None:
        super().__init__(method_executor, signal_registry, config, calibration_orchestrator)
        self._validate_calibrations()

    def execute(self, doc, method_executor):
        method_sequence = [
            ('IndustrialPolicyProcessor', '_match_patterns_in_sentences'),
            ('IndustrialPolicyProcessor', 'process'),
            ('PolicyTextProcessor', 'segment_into_sentences'),
            ('PolicyTextProcessor', 'extract_contextual_window'),
            ('BayesianEvidenceScorer', 'compute_evidence_score'),
            ('PolicyContradictionDetector', '_generate_embeddings'),
            ('PolicyContradictionDetector', '_calculate_similarity'),
            ('PolicyContradictionDetector', '_identify_dependencies'),
            ('PolicyContradictionDetector', '_determine_semantic_role'),
            ('PolicyContradictionDetector', '_calculate_global_semantic_coherence'),
            ('PolicyContradictionDetector', '_get_context_window'),
            ('PolicyContradictionDetector', '_build_knowledge_graph'),
            ('BayesianConfidenceCalculator', 'calculate_posterior'),
            ('SemanticAnalyzer', '_classify_cross_cutting_themes'),
            ('SemanticAnalyzer', '_classify_policy_domain'),
            ('SemanticAnalyzer', 'extract_semantic_cube'),
            ('SemanticAnalyzer', '_process_segment'),
            ('SemanticAnalyzer', '_vectorize_segments'),
            ('SemanticAnalyzer', '_calculate_semantic_complexity'),
            ('MunicipalOntology', '__init__'),
            ('PolicyAnalysisEmbedder', 'semantic_search'),
            ('PolicyAnalysisEmbedder', '_filter_by_pdq'),
            ('PolicyAnalysisEmbedder', 'compare_policy_interventions'),
            ('AdvancedSemanticChunker', '_infer_pdq_context'),
        ]
        return self.execute_with_optimization(doc, method_executor, method_sequence)

    def _extract(self, results):
        vals = [v for v in results.values() if v is not None]
        return vals[:4] if vals else []

# ============================================================================
# ORCHESTRATOR
# ============================================================================

class FrontierExecutorOrchestrator:
    """Orchestrator managing frontier-enhanced executors"""

    def __init__(self) -> None:
        self.executors = {
            'D1Q1': D1Q1_Executor,
            'D1Q2': D1Q2_Executor,
            'D1Q3': D1Q3_Executor,
            'D1Q4': D1Q4_Executor,
            'D1Q5': D1Q5_Executor,
            'D2Q1': D2Q1_Executor,
            'D2Q2': D2Q2_Executor,
            'D2Q3': D2Q3_Executor,
            'D2Q4': D2Q4_Executor,
            'D2Q5': D2Q5_Executor,
            'D3Q1': D3Q1_Executor,
            'D3Q2': D3Q2_Executor,
            'D3Q3': D3Q3_Executor,
            'D3Q4': D3Q4_Executor,
            'D3Q5': D3Q5_Executor,
            'D4Q1': D4Q1_Executor,
            'D4Q2': D4Q2_Executor,
            'D4Q3': D4Q3_Executor,
            'D4Q4': D4Q4_Executor,
            'D4Q5': D4Q5_Executor,
            'D5Q1': D5Q1_Executor,
            'D5Q2': D5Q2_Executor,
            'D5Q3': D5Q3_Executor,
            'D5Q4': D5Q4_Executor,
            'D5Q5': D5Q5_Executor,
            'D6Q1': D6Q1_Executor,
            'D6Q2': D6Q2_Executor,
            'D6Q3': D6Q3_Executor,
            'D6Q4': D6Q4_Executor,
            'D6Q5': D6Q5_Executor,
        }

        self.global_causal_graph = CausalGraph(num_variables=30)
        self.global_meta_learner = MetaLearningStrategy(num_strategies=10)

    def execute_question(self, question_id: str, doc, method_executor) -> dict[str, Any]:
        """Execute specific question with frontier optimizations"""
        if question_id not in self.executors:
            logger.error(f"Unknown question ID: {question_id}")
            raise ValueError(f"Unknown question ID: {question_id}")

        logger.info(f"Executing question {question_id}")
        start_time = time.time()

        executor_class = self.executors[question_id]
        executor = executor_class(method_executor)

        result = executor.execute(doc, method_executor)

        execution_time = time.time() - start_time
        logger.info(f"Question {question_id} completed in {execution_time:.3f}s")

        return result

    def batch_execute(self, question_ids: list[str], doc, method_executor) -> dict[str, Any]:
        """Execute multiple questions with cross-question optimization"""
        logger.info(f"Starting batch execution of {len(question_ids)} questions")
        batch_start = time.time()

        results = {}

        execution_order = self._optimize_execution_order(question_ids)
        logger.info(f"Optimized execution order: {execution_order}")

        for qid in execution_order:
            results[qid] = self.execute_question(qid, doc, method_executor)

        batch_time = time.time() - batch_start
        logger.info(f"Batch execution completed in {batch_time:.3f}s")

        return results

    def _optimize_execution_order(self, question_ids: list[str], rng: np.random.Generator | None = None) -> list[str]:
        """Optimize execution order using causal inference"""
        rng = _ensure_rng(rng)
        if len(question_ids) <= 1:
            return question_ids

        # Create a temporary causal graph for the actual number of questions
        n_questions = len(question_ids)
        temp_graph = CausalGraph(num_variables=n_questions)

        # Generate synthetic data for structure learning
        data = rng.standard_normal((max(100, n_questions * 10), n_questions))
        temp_graph.learn_structure(data, alpha=0.05)

        # Get optimal execution order
        indices = temp_graph.get_execution_order()

        # Map indices to question IDs
        return [question_ids[i] for i in indices if i < len(question_ids)]

# Backwards compatibility alias
DataFlowExecutor = AdvancedDataFlowExecutor

# Export all executor classes and orchestrator
__all__ = [
    # Executor classes for all 30 questions
    'D1Q1_Executor',
    'D1Q2_Executor',
    'D1Q3_Executor',
    'D1Q4_Executor',
    'D1Q5_Executor',
    'D2Q1_Executor',
    'D2Q2_Executor',
    'D2Q3_Executor',
    'D2Q4_Executor',
    'D2Q5_Executor',
    'D3Q1_Executor',
    'D3Q2_Executor',
    'D3Q3_Executor',
    'D3Q4_Executor',
    'D3Q5_Executor',
    'D4Q1_Executor',
    'D4Q2_Executor',
    'D4Q3_Executor',
    'D4Q4_Executor',
    'D4Q5_Executor',
    'D5Q1_Executor',
    'D5Q2_Executor',
    'D5Q3_Executor',
    'D5Q4_Executor',
    'D5Q5_Executor',
    'D6Q1_Executor',
    'D6Q2_Executor',
    'D6Q3_Executor',
    'D6Q4_Executor',
    'D6Q5_Executor',
    # Main orchestrator
    'FrontierExecutorOrchestrator',
    # Base classes
    'ExecutorBase',
    'ValidationResult',
    'AdvancedDataFlowExecutor',
    'DataFlowExecutor',  # Backwards compatibility alias
]
